{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Share Price Predictor\n",
    "\n",
    "## Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ticker: The stock we intend to predict, e.g Tesla would be TSLA.\n",
    "- n_steps: The timeframe we intend to use for training, e.g. 50 would use the last 50 days' prices.\n",
    "- scale: Boolean which indicates whether we are want to scale our share prices between 0 and 1 or not.\n",
    "- lookup_step: The number of days into the future which we intend to predict for.\n",
    "- The adjcolse, volume, open, high and low indicators will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
    "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
    "    last_sequence = list(sequences) + list(last_sequence)\n",
    "    # shift the last sequence by -1\n",
    "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # reshape X to fit the neural network\n",
    "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
    "    # split the dataset\n",
    "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
    "    # return the result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window size or the sequence length\n",
    "N_STEPS = 100\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 1\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 3\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 400\n",
    "# Apple stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory for saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3749e-04 - mean_absolute_error: 0.0197\n",
      "Epoch 00001: val_loss improved from inf to 0.00022, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 8.3749e-04 - mean_absolute_error: 0.0197 - val_loss: 2.2464e-04 - val_mean_absolute_error: 0.0089\n",
      "Epoch 2/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 5.4730e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00002: val_loss improved from 0.00022 to 0.00017, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 14s 115ms/step - loss: 5.4730e-04 - mean_absolute_error: 0.0151 - val_loss: 1.7473e-04 - val_mean_absolute_error: 0.0072\n",
      "Epoch 3/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 5.3394e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00003: val_loss improved from 0.00017 to 0.00016, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 5.3394e-04 - mean_absolute_error: 0.0151 - val_loss: 1.6364e-04 - val_mean_absolute_error: 0.0071\n",
      "Epoch 4/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 5.9814e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 00004: val_loss improved from 0.00016 to 0.00015, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 14s 116ms/step - loss: 5.9814e-04 - mean_absolute_error: 0.0158 - val_loss: 1.5268e-04 - val_mean_absolute_error: 0.0073\n",
      "Epoch 5/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 4.8379e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00005: val_loss did not improve from 0.00015\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 4.8379e-04 - mean_absolute_error: 0.0146 - val_loss: 3.2512e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 6/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 3.9212e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00006: val_loss did not improve from 0.00015\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 3.9212e-04 - mean_absolute_error: 0.0132 - val_loss: 2.7578e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 7/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 3.2655e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00007: val_loss did not improve from 0.00015\n",
      "124/124 [==============================] - 14s 116ms/step - loss: 3.2655e-04 - mean_absolute_error: 0.0126 - val_loss: 2.8281e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 8/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 3.9875e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 00008: val_loss did not improve from 0.00015\n",
      "124/124 [==============================] - 14s 116ms/step - loss: 3.9875e-04 - mean_absolute_error: 0.0133 - val_loss: 1.7318e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 9/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.8176e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00009: val_loss improved from 0.00015 to 0.00009, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 2.8176e-04 - mean_absolute_error: 0.0116 - val_loss: 8.9362e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 10/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 3.0991e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 00010: val_loss improved from 0.00009 to 0.00006, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 23s 188ms/step - loss: 3.0991e-04 - mean_absolute_error: 0.0122 - val_loss: 6.1893e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 11/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.8119e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00011: val_loss did not improve from 0.00006\n",
      "124/124 [==============================] - 19s 151ms/step - loss: 2.8119e-04 - mean_absolute_error: 0.0119 - val_loss: 9.3698e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 12/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.8199e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 00012: val_loss improved from 0.00006 to 0.00004, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 24s 192ms/step - loss: 2.8199e-04 - mean_absolute_error: 0.0118 - val_loss: 4.0892e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 13/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.1237e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00013: val_loss improved from 0.00004 to 0.00004, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 20s 162ms/step - loss: 2.1237e-04 - mean_absolute_error: 0.0109 - val_loss: 3.5183e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 14/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.1202e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00014: val_loss did not improve from 0.00004\n",
      "124/124 [==============================] - 27s 221ms/step - loss: 2.1202e-04 - mean_absolute_error: 0.0106 - val_loss: 5.2943e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 15/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.7918e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00015: val_loss did not improve from 0.00004\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 1.7918e-04 - mean_absolute_error: 0.0102 - val_loss: 3.9637e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 16/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.1439e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00016: val_loss did not improve from 0.00004\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 2.1439e-04 - mean_absolute_error: 0.0105 - val_loss: 1.3072e-04 - val_mean_absolute_error: 0.0090\n",
      "Epoch 17/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.3498e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00017: val_loss did not improve from 0.00004\n",
      "124/124 [==============================] - 16s 133ms/step - loss: 2.3498e-04 - mean_absolute_error: 0.0115 - val_loss: 6.6585e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 18/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.8160e-04 - mean_absolute_error: 0.010 - ETA: 0s - loss: 1.8151e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00018: val_loss improved from 0.00004 to 0.00003, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 17s 136ms/step - loss: 1.8151e-04 - mean_absolute_error: 0.0104 - val_loss: 2.5526e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 19/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.6552e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00019: val_loss improved from 0.00003 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 17s 136ms/step - loss: 1.6552e-04 - mean_absolute_error: 0.0100 - val_loss: 2.3951e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 20/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.7099e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00020: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 21s 166ms/step - loss: 1.7099e-04 - mean_absolute_error: 0.0103 - val_loss: 5.3387e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 21/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.8213e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00021: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 22s 179ms/step - loss: 1.8213e-04 - mean_absolute_error: 0.0105 - val_loss: 6.9053e-05 - val_mean_absolute_error: 0.0082\n",
      "Epoch 22/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.8034e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00022: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 1.8034e-04 - mean_absolute_error: 0.0103 - val_loss: 3.4453e-05 - val_mean_absolute_error: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4492e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00023: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 122ms/step - loss: 1.4492e-04 - mean_absolute_error: 0.0094 - val_loss: 3.4392e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 24/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.7546e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00024: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 122ms/step - loss: 1.7546e-04 - mean_absolute_error: 0.0103 - val_loss: 6.8466e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 25/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.5842e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00025: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 1.5842e-04 - mean_absolute_error: 0.0098 - val_loss: 2.6602e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 26/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.9053e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00026: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.9053e-04 - mean_absolute_error: 0.0109 - val_loss: 2.6292e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 27/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.5979e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00027: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.5979e-04 - mean_absolute_error: 0.0103 - val_loss: 4.4218e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 28/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.5051e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00028: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.5051e-04 - mean_absolute_error: 0.0099 - val_loss: 2.7693e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 29/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4833e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00029: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.4833e-04 - mean_absolute_error: 0.0097 - val_loss: 5.1803e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 30/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4954e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00030: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 1.4954e-04 - mean_absolute_error: 0.0098 - val_loss: 2.5494e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 31/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.3488e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00031: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.3488e-04 - mean_absolute_error: 0.0095 - val_loss: 4.3541e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 32/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.3788e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00032: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.3788e-04 - mean_absolute_error: 0.0096 - val_loss: 4.0411e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 33/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2547e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00033: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 1.2547e-04 - mean_absolute_error: 0.0090 - val_loss: 5.3251e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 34/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.5331e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00034: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 133ms/step - loss: 1.5331e-04 - mean_absolute_error: 0.0098 - val_loss: 7.7904e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 35/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2062e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00035: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 1.2062e-04 - mean_absolute_error: 0.0089 - val_loss: 3.6544e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 36/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.5532e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00036: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 1.5532e-04 - mean_absolute_error: 0.0099 - val_loss: 2.8863e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 37/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2403e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00037: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 137ms/step - loss: 1.2403e-04 - mean_absolute_error: 0.0087 - val_loss: 1.9083e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 38/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.3053e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00038: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.3053e-04 - mean_absolute_error: 0.0093 - val_loss: 2.4582e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 39/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2593e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00039: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 1.2593e-04 - mean_absolute_error: 0.0090 - val_loss: 4.4346e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 40/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.3217e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00040: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 1.3217e-04 - mean_absolute_error: 0.0096 - val_loss: 1.0721e-04 - val_mean_absolute_error: 0.0075\n",
      "Epoch 41/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4383e-04 - mean_absolute_error: 0.0099- ETA:\n",
      "Epoch 00041: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 1.4383e-04 - mean_absolute_error: 0.0099 - val_loss: 2.5091e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 42/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1837e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00042: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 1.1837e-04 - mean_absolute_error: 0.0089 - val_loss: 4.1479e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 43/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4090e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00043: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 1.4090e-04 - mean_absolute_error: 0.0094 - val_loss: 6.1953e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 44/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1387e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00044: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 139ms/step - loss: 1.1387e-04 - mean_absolute_error: 0.0087 - val_loss: 8.3564e-05 - val_mean_absolute_error: 0.0092\n",
      "Epoch 45/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2421e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00045: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.2421e-04 - mean_absolute_error: 0.0090 - val_loss: 2.3738e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 46/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.3242e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00046: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.3242e-04 - mean_absolute_error: 0.0098 - val_loss: 4.2902e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 47/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2459e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00047: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.2459e-04 - mean_absolute_error: 0.0089 - val_loss: 2.0611e-05 - val_mean_absolute_error: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1147e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00048: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 1.1147e-04 - mean_absolute_error: 0.0083 - val_loss: 2.0452e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 49/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1135e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00049: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 1.1135e-04 - mean_absolute_error: 0.0086 - val_loss: 1.9134e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 50/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4637e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00050: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 20s 163ms/step - loss: 1.4637e-04 - mean_absolute_error: 0.0098 - val_loss: 5.5700e-05 - val_mean_absolute_error: 0.0085\n",
      "Epoch 51/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4210e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00051: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 1.4210e-04 - mean_absolute_error: 0.0092 - val_loss: 2.5910e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 52/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1540e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00052: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 1.1540e-04 - mean_absolute_error: 0.0086 - val_loss: 2.7603e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 53/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1702e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00053: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 23s 184ms/step - loss: 1.1702e-04 - mean_absolute_error: 0.0088 - val_loss: 6.9392e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 54/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1403e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00054: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 1.1403e-04 - mean_absolute_error: 0.0087 - val_loss: 7.8444e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 55/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2695e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00055: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 1.2695e-04 - mean_absolute_error: 0.0091 - val_loss: 9.0318e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 56/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.3211e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00056: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 142ms/step - loss: 1.3211e-04 - mean_absolute_error: 0.0096 - val_loss: 2.5852e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 57/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1518e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00057: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 1.1518e-04 - mean_absolute_error: 0.0089 - val_loss: 1.9193e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 58/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1374e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00058: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.1374e-04 - mean_absolute_error: 0.0088 - val_loss: 2.1928e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 59/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0640e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00059: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.0640e-04 - mean_absolute_error: 0.0084 - val_loss: 6.0476e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 60/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9871e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00060: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 9.9871e-05 - mean_absolute_error: 0.0083 - val_loss: 2.8863e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 61/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2417e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00061: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.2417e-04 - mean_absolute_error: 0.0089 - val_loss: 4.7686e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 62/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1744e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00062: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1744e-04 - mean_absolute_error: 0.0087 - val_loss: 2.6212e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 63/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4742e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00063: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 125ms/step - loss: 1.4742e-04 - mean_absolute_error: 0.0099 - val_loss: 9.1375e-05 - val_mean_absolute_error: 0.0089\n",
      "Epoch 64/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1640e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00064: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 1.1640e-04 - mean_absolute_error: 0.0088 - val_loss: 1.9310e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 65/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3348e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00065: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 9.3348e-05 - mean_absolute_error: 0.0079 - val_loss: 7.1687e-05 - val_mean_absolute_error: 0.0096\n",
      "Epoch 66/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0257e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00066: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.0257e-04 - mean_absolute_error: 0.0083 - val_loss: 9.5682e-05 - val_mean_absolute_error: 0.0091\n",
      "Epoch 67/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1713e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00067: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1713e-04 - mean_absolute_error: 0.0088 - val_loss: 7.4920e-05 - val_mean_absolute_error: 0.0109\n",
      "Epoch 68/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2095e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00068: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 19s 149ms/step - loss: 1.2095e-04 - mean_absolute_error: 0.0089 - val_loss: 2.1791e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 69/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2294e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00069: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.2294e-04 - mean_absolute_error: 0.0089 - val_loss: 8.4330e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 70/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1998e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00070: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 20s 157ms/step - loss: 1.1998e-04 - mean_absolute_error: 0.0092 - val_loss: 2.2093e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 71/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2568e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00071: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 1.2568e-04 - mean_absolute_error: 0.0091 - val_loss: 7.6920e-05 - val_mean_absolute_error: 0.0095\n",
      "Epoch 72/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2077e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00072: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 1.2077e-04 - mean_absolute_error: 0.0093 - val_loss: 4.6167e-05 - val_mean_absolute_error: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1466e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00073: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 1.1466e-04 - mean_absolute_error: 0.0085 - val_loss: 6.6548e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 74/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2002e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00074: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 133ms/step - loss: 1.2002e-04 - mean_absolute_error: 0.0091 - val_loss: 3.1153e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 75/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1149e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00075: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 19s 154ms/step - loss: 1.1149e-04 - mean_absolute_error: 0.0088 - val_loss: 6.1091e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 76/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0908e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00076: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 1.0908e-04 - mean_absolute_error: 0.0084 - val_loss: 6.5777e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 77/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0688e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00077: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 1.0688e-04 - mean_absolute_error: 0.0085 - val_loss: 2.4092e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 78/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7198e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00078: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 9.7198e-05 - mean_absolute_error: 0.0081 - val_loss: 6.6060e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 79/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0942e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00079: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 21s 167ms/step - loss: 1.0942e-04 - mean_absolute_error: 0.0085 - val_loss: 2.5730e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 80/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1496e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00080: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 1.1496e-04 - mean_absolute_error: 0.0087 - val_loss: 4.5959e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 81/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0625e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00081: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 25s 198ms/step - loss: 1.0625e-04 - mean_absolute_error: 0.0086 - val_loss: 1.7229e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 82/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1829e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00082: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 20s 160ms/step - loss: 1.1829e-04 - mean_absolute_error: 0.0088 - val_loss: 3.9970e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 83/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1911e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00083: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.1911e-04 - mean_absolute_error: 0.0089 - val_loss: 2.1239e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 84/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1020e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00084: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1020e-04 - mean_absolute_error: 0.0086 - val_loss: 1.8056e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 85/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0572e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00085: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.0572e-04 - mean_absolute_error: 0.0083 - val_loss: 2.3997e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 86/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0231e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00086: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 1.0231e-04 - mean_absolute_error: 0.0083 - val_loss: 5.2557e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 87/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1546e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00087: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1546e-04 - mean_absolute_error: 0.0085 - val_loss: 5.4047e-05 - val_mean_absolute_error: 0.0074\n",
      "Epoch 88/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1661e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00088: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1661e-04 - mean_absolute_error: 0.0086 - val_loss: 1.7184e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 89/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7160e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00089: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 8.7160e-05 - mean_absolute_error: 0.0077 - val_loss: 4.8621e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 90/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1844e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00090: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 1.1844e-04 - mean_absolute_error: 0.0089 - val_loss: 6.8166e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 91/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1124e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00091: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1124e-04 - mean_absolute_error: 0.0087 - val_loss: 2.0978e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 92/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0335e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00092: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.0335e-04 - mean_absolute_error: 0.0084 - val_loss: 4.3248e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 93/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0402e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00093: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.0402e-04 - mean_absolute_error: 0.0082 - val_loss: 3.3171e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 94/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0211e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00094: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 1.0211e-04 - mean_absolute_error: 0.0083 - val_loss: 9.0958e-05 - val_mean_absolute_error: 0.0075\n",
      "Epoch 95/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0822e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00095: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.0822e-04 - mean_absolute_error: 0.0084 - val_loss: 1.3393e-04 - val_mean_absolute_error: 0.0083\n",
      "Epoch 96/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1373e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00096: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 1.1373e-04 - mean_absolute_error: 0.0087 - val_loss: 1.2769e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 97/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0603e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00097: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 1.0603e-04 - mean_absolute_error: 0.0088 - val_loss: 1.6320e-05 - val_mean_absolute_error: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0395e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00098: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 1.0395e-04 - mean_absolute_error: 0.0083 - val_loss: 4.5065e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 99/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0450e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00099: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 1.0450e-04 - mean_absolute_error: 0.0086 - val_loss: 5.5364e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 100/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0266e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00100: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 19s 149ms/step - loss: 1.0266e-04 - mean_absolute_error: 0.0083 - val_loss: 7.1334e-05 - val_mean_absolute_error: 0.0069\n",
      "Epoch 101/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1243e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00101: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 1.1243e-04 - mean_absolute_error: 0.0086 - val_loss: 2.8370e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 102/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0077e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00102: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 1.0077e-04 - mean_absolute_error: 0.0081 - val_loss: 2.6796e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 103/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2901e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00103: val_loss did not improve from 0.00002\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 1.2901e-04 - mean_absolute_error: 0.0092 - val_loss: 7.6950e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 104/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1862e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00104: val_loss improved from 0.00002 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 20s 164ms/step - loss: 1.1862e-04 - mean_absolute_error: 0.0088 - val_loss: 1.4811e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 105/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5004e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00105: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 20s 159ms/step - loss: 9.5004e-05 - mean_absolute_error: 0.0080 - val_loss: 1.7653e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 106/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0798e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00106: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 172ms/step - loss: 1.0798e-04 - mean_absolute_error: 0.0084 - val_loss: 2.5124e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 107/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2199e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00107: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 23s 182ms/step - loss: 1.2199e-04 - mean_absolute_error: 0.0093 - val_loss: 1.8126e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 108/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8132e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00108: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 152ms/step - loss: 9.8132e-05 - mean_absolute_error: 0.0082 - val_loss: 3.6079e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 109/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8098e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00109: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 9.8098e-05 - mean_absolute_error: 0.0083 - val_loss: 2.4743e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 110/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0480e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00110: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 136ms/step - loss: 1.0480e-04 - mean_absolute_error: 0.0086 - val_loss: 9.7653e-05 - val_mean_absolute_error: 0.0076\n",
      "Epoch 111/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2663e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00111: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 1.2663e-04 - mean_absolute_error: 0.0090 - val_loss: 2.3136e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 112/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.2076e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00112: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.2076e-04 - mean_absolute_error: 0.0086 - val_loss: 4.4565e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 113/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1413e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00113: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.1413e-04 - mean_absolute_error: 0.0087 - val_loss: 1.7243e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 114/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5466e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00114: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 9.5466e-05 - mean_absolute_error: 0.0079 - val_loss: 3.5459e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 115/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0031e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00115: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 1.0031e-04 - mean_absolute_error: 0.0081 - val_loss: 1.1637e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 116/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0078e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00116: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 1.0078e-04 - mean_absolute_error: 0.0083 - val_loss: 4.3514e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 117/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0756e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00117: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 1.0756e-04 - mean_absolute_error: 0.0084 - val_loss: 1.2003e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 118/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8896e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00118: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 9.8896e-05 - mean_absolute_error: 0.0080 - val_loss: 3.2548e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 119/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0296e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00119: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 125ms/step - loss: 1.0296e-04 - mean_absolute_error: 0.0081 - val_loss: 2.7345e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 120/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2505e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00120: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 9.2505e-05 - mean_absolute_error: 0.0080 - val_loss: 2.9026e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 121/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8832e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00121: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 8.8832e-05 - mean_absolute_error: 0.0080 - val_loss: 1.5505e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 122/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5803e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00122: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 9.5803e-05 - mean_absolute_error: 0.0080 - val_loss: 3.3537e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 123/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0566e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00123: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 117ms/step - loss: 1.0566e-04 - mean_absolute_error: 0.0085 - val_loss: 1.3636e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 124/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0034e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00124: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 1.0034e-04 - mean_absolute_error: 0.0082 - val_loss: 2.8742e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 125/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7712e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00125: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 9.7712e-05 - mean_absolute_error: 0.0078 - val_loss: 2.3853e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 126/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.9536e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00126: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 8.9536e-05 - mean_absolute_error: 0.0078 - val_loss: 3.5444e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 127/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0250e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00127: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 1.0250e-04 - mean_absolute_error: 0.0082 - val_loss: 2.5614e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 128/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0510e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00128: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 1.0510e-04 - mean_absolute_error: 0.0084 - val_loss: 9.0490e-05 - val_mean_absolute_error: 0.0079\n",
      "Epoch 129/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4068e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00129: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 9.4068e-05 - mean_absolute_error: 0.0082 - val_loss: 2.4741e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 130/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9574e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00130: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 9.9574e-05 - mean_absolute_error: 0.0080 - val_loss: 5.3578e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 131/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6494e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00131: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 9.6494e-05 - mean_absolute_error: 0.0079 - val_loss: 2.2789e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 132/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7039e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00132: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 9.7039e-05 - mean_absolute_error: 0.0077 - val_loss: 3.3782e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 133/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0302e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00133: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 1.0302e-04 - mean_absolute_error: 0.0082 - val_loss: 1.9387e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 134/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6977e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00134: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 133ms/step - loss: 9.6977e-05 - mean_absolute_error: 0.0080 - val_loss: 6.7450e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 135/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0216e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00135: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 20s 159ms/step - loss: 1.0216e-04 - mean_absolute_error: 0.0082 - val_loss: 3.8905e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 136/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9869e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00136: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 9.9869e-05 - mean_absolute_error: 0.0080 - val_loss: 4.6489e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 137/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0646e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00137: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 9.0646e-05 - mean_absolute_error: 0.0080 - val_loss: 1.7953e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 138/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0225e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00138: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 1.0225e-04 - mean_absolute_error: 0.0082 - val_loss: 2.0470e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 139/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7417e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00139: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 109ms/step - loss: 9.7417e-05 - mean_absolute_error: 0.0081 - val_loss: 3.1573e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 140/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2971e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00140: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 109ms/step - loss: 9.2971e-05 - mean_absolute_error: 0.0079 - val_loss: 2.1484e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 141/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0065e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00141: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 9.0065e-05 - mean_absolute_error: 0.0078 - val_loss: 1.7105e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 142/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1010e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00142: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.1010e-05 - mean_absolute_error: 0.0074 - val_loss: 1.5198e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 143/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7116e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00143: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.7116e-05 - mean_absolute_error: 0.0079 - val_loss: 5.9223e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 144/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4775e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00144: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 9.4775e-05 - mean_absolute_error: 0.0081 - val_loss: 2.7705e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 145/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0173e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00145: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 1.0173e-04 - mean_absolute_error: 0.0084 - val_loss: 1.8182e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 146/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0131e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00146: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 1.0131e-04 - mean_absolute_error: 0.0081 - val_loss: 5.3717e-05 - val_mean_absolute_error: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4411e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00147: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.4411e-05 - mean_absolute_error: 0.0080 - val_loss: 2.4936e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 148/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0009e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00148: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0009e-04 - mean_absolute_error: 0.0082 - val_loss: 2.7060e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 149/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6770e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00149: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 113ms/step - loss: 9.6770e-05 - mean_absolute_error: 0.0080 - val_loss: 5.0648e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 150/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3080e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00150: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.3080e-05 - mean_absolute_error: 0.0082 - val_loss: 1.7572e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 151/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0328e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00151: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 1.0328e-04 - mean_absolute_error: 0.0082 - val_loss: 4.8749e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 152/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2197e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00152: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.2197e-05 - mean_absolute_error: 0.0079 - val_loss: 3.3701e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 153/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8063e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00153: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.8063e-05 - mean_absolute_error: 0.0081 - val_loss: 1.8827e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 154/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.1829e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00154: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 9.1829e-05 - mean_absolute_error: 0.0077 - val_loss: 2.3634e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 155/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0334e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00155: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.0334e-05 - mean_absolute_error: 0.0080 - val_loss: 1.8895e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 156/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0475e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00156: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 9.0475e-05 - mean_absolute_error: 0.0080 - val_loss: 2.0512e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 157/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7830e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00157: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 8.7830e-05 - mean_absolute_error: 0.0078 - val_loss: 1.1508e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 158/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3080e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00158: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 9.3080e-05 - mean_absolute_error: 0.0078 - val_loss: 2.3998e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 159/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8342e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00159: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.8342e-05 - mean_absolute_error: 0.0080 - val_loss: 2.8871e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 160/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0124e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00160: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0124e-04 - mean_absolute_error: 0.0082 - val_loss: 2.1567e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 161/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9094e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00161: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.9094e-05 - mean_absolute_error: 0.0079 - val_loss: 4.7974e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 162/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0727e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00162: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 9.0727e-05 - mean_absolute_error: 0.0077 - val_loss: 2.1393e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 163/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0426e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00163: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0426e-04 - mean_absolute_error: 0.0084 - val_loss: 2.2064e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 164/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8297e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00164: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 8.8297e-05 - mean_absolute_error: 0.0076 - val_loss: 4.3819e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 165/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8741e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00165: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.8741e-05 - mean_absolute_error: 0.0080 - val_loss: 1.8190e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 166/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3498e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00166: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 8.3498e-05 - mean_absolute_error: 0.0076 - val_loss: 3.7736e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 167/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5035e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00167: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.5035e-05 - mean_absolute_error: 0.0076 - val_loss: 1.8681e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 168/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0047e-04 - mean_absolute_error: 0.0079\n",
      "Epoch 00168: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0047e-04 - mean_absolute_error: 0.0079 - val_loss: 2.8008e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 169/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3743e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00169: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.3743e-05 - mean_absolute_error: 0.0078 - val_loss: 2.2347e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 170/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.1424e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00170: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.1424e-05 - mean_absolute_error: 0.0076 - val_loss: 2.9220e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 171/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8467e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00171: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.8467e-05 - mean_absolute_error: 0.0080 - val_loss: 4.7327e-05 - val_mean_absolute_error: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2438e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00172: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.2438e-05 - mean_absolute_error: 0.0080 - val_loss: 1.3715e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 173/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2421e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00173: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.2421e-05 - mean_absolute_error: 0.0080 - val_loss: 1.1493e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 174/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1429e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00174: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 8.1429e-05 - mean_absolute_error: 0.0075 - val_loss: 1.1712e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 175/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4505e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00175: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.4505e-05 - mean_absolute_error: 0.0077 - val_loss: 3.2329e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 176/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.9102e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00176: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.9102e-05 - mean_absolute_error: 0.0077 - val_loss: 2.2139e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 177/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5203e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00177: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.5203e-05 - mean_absolute_error: 0.0081 - val_loss: 1.6185e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 178/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0422e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00178: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 1.0422e-04 - mean_absolute_error: 0.0082 - val_loss: 1.7288e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 179/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0213e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00179: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 9.0213e-05 - mean_absolute_error: 0.0078 - val_loss: 5.8282e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 180/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0099e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00180: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0099e-04 - mean_absolute_error: 0.0081 - val_loss: 3.9180e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 181/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0099e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00181: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0099e-04 - mean_absolute_error: 0.0082 - val_loss: 1.2177e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 182/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.0362e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 00182: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 1.0362e-04 - mean_absolute_error: 0.0080 - val_loss: 2.4761e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 183/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0498e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00183: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.0498e-05 - mean_absolute_error: 0.0078 - val_loss: 4.6219e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 184/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.1717e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00184: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 9.1717e-05 - mean_absolute_error: 0.0078 - val_loss: 2.6996e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 185/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6109e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00185: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 8.6109e-05 - mean_absolute_error: 0.0077 - val_loss: 1.1025e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 186/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7271e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00186: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.7271e-05 - mean_absolute_error: 0.0075 - val_loss: 3.5423e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 187/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0136e-05 - mean_absolute_error: 0.0076- ETA: 0s - loss: 8.0268e-05 - mean_absolute_error: 0.007\n",
      "Epoch 00187: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.0136e-05 - mean_absolute_error: 0.0076 - val_loss: 4.9142e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 188/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5704e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00188: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.5704e-05 - mean_absolute_error: 0.0079 - val_loss: 3.7489e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 189/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9197e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00189: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.9197e-05 - mean_absolute_error: 0.0080 - val_loss: 1.1560e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 190/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2499e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00190: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.2499e-05 - mean_absolute_error: 0.0079 - val_loss: 1.2648e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 191/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3322e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00191: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.3322e-05 - mean_absolute_error: 0.0076 - val_loss: 6.3737e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 192/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.9625e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00192: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.9625e-05 - mean_absolute_error: 0.0081 - val_loss: 1.7382e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 193/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5730e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00193: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.5730e-05 - mean_absolute_error: 0.0076 - val_loss: 2.0690e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 194/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6876e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00194: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 114ms/step - loss: 9.6876e-05 - mean_absolute_error: 0.0080 - val_loss: 4.3690e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 195/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.8461e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00195: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 109ms/step - loss: 9.8461e-05 - mean_absolute_error: 0.0081 - val_loss: 3.4324e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 196/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7122e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00196: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.7122e-05 - mean_absolute_error: 0.0075 - val_loss: 1.8758e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 197/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6825e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00197: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 8.6825e-05 - mean_absolute_error: 0.0077 - val_loss: 1.4348e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 198/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3683e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00198: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.3683e-05 - mean_absolute_error: 0.0077 - val_loss: 2.9536e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 199/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7332e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00199: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 9.7332e-05 - mean_absolute_error: 0.0080 - val_loss: 1.3632e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 200/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0014e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00200: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 9.0014e-05 - mean_absolute_error: 0.0076 - val_loss: 3.2449e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 201/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6648e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00201: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 9.6648e-05 - mean_absolute_error: 0.0080 - val_loss: 1.4249e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 202/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4667e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00202: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 110ms/step - loss: 9.4667e-05 - mean_absolute_error: 0.0077 - val_loss: 1.2053e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 203/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0970e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00203: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 8.0970e-05 - mean_absolute_error: 0.0074 - val_loss: 1.1770e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 204/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3504e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00204: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 8.3504e-05 - mean_absolute_error: 0.0075 - val_loss: 1.6196e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 205/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5178e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00205: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 9.5178e-05 - mean_absolute_error: 0.0078 - val_loss: 1.5733e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 206/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6167e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00206: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 141ms/step - loss: 8.6167e-05 - mean_absolute_error: 0.0076 - val_loss: 1.8527e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 207/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5906e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00207: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 7.5906e-05 - mean_absolute_error: 0.0073 - val_loss: 1.6017e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 208/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0459e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00208: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 8.0459e-05 - mean_absolute_error: 0.0073 - val_loss: 5.6557e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 209/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8094e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00209: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 8.8094e-05 - mean_absolute_error: 0.0076 - val_loss: 1.6860e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 210/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6661e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00210: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 22s 176ms/step - loss: 8.6661e-05 - mean_absolute_error: 0.0075 - val_loss: 5.9259e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 211/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2919e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00211: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 157ms/step - loss: 9.2919e-05 - mean_absolute_error: 0.0078 - val_loss: 3.8192e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 212/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.5605e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00212: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 153ms/step - loss: 9.5605e-05 - mean_absolute_error: 0.0080 - val_loss: 2.2307e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 213/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3507e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00213: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 8.3507e-05 - mean_absolute_error: 0.0075 - val_loss: 2.1174e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 214/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.4147e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00214: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 9.4147e-05 - mean_absolute_error: 0.0079 - val_loss: 1.4329e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 215/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2098e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00215: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 8.2098e-05 - mean_absolute_error: 0.0074 - val_loss: 1.6590e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 216/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0857e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00216: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 19s 155ms/step - loss: 8.0857e-05 - mean_absolute_error: 0.0073 - val_loss: 1.0813e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 217/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1895e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00217: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 8.1895e-05 - mean_absolute_error: 0.0073 - val_loss: 4.8509e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 218/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9387e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00218: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 7.9387e-05 - mean_absolute_error: 0.0074 - val_loss: 3.7810e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 219/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1729e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00219: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 172ms/step - loss: 8.1729e-05 - mean_absolute_error: 0.0076 - val_loss: 2.3696e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 220/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.9687e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00220: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 141ms/step - loss: 8.9687e-05 - mean_absolute_error: 0.0075 - val_loss: 2.3201e-05 - val_mean_absolute_error: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7548e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00221: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 7.7548e-05 - mean_absolute_error: 0.0073 - val_loss: 1.8379e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 222/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3527e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00222: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 9.3527e-05 - mean_absolute_error: 0.0078 - val_loss: 3.0607e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 223/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.9478e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00223: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 8.9478e-05 - mean_absolute_error: 0.0076 - val_loss: 3.8150e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 224/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4182e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00224: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 8.4182e-05 - mean_absolute_error: 0.0076 - val_loss: 1.2482e-04 - val_mean_absolute_error: 0.0093\n",
      "Epoch 225/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0842e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00225: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 9.0842e-05 - mean_absolute_error: 0.0076 - val_loss: 2.9182e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 226/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0924e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00226: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 8.0924e-05 - mean_absolute_error: 0.0074 - val_loss: 1.7505e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 227/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8122e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00227: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 8.8122e-05 - mean_absolute_error: 0.0077 - val_loss: 2.0732e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 228/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9399e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00228: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 7.9399e-05 - mean_absolute_error: 0.0072 - val_loss: 2.4851e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 229/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4348e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00229: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 8.4348e-05 - mean_absolute_error: 0.0075 - val_loss: 1.9667e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 230/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2148e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00230: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 8.2148e-05 - mean_absolute_error: 0.0072 - val_loss: 7.0289e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 231/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9855e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00231: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 7.9855e-05 - mean_absolute_error: 0.0074 - val_loss: 2.2949e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 232/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1295e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00232: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 8.1295e-05 - mean_absolute_error: 0.0073 - val_loss: 2.8048e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 233/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8758e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00233: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 7.8758e-05 - mean_absolute_error: 0.0073 - val_loss: 5.0808e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 234/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8569e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00234: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 148ms/step - loss: 7.8569e-05 - mean_absolute_error: 0.0074 - val_loss: 2.1538e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 235/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2650e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00235: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 137ms/step - loss: 8.2650e-05 - mean_absolute_error: 0.0073 - val_loss: 2.5628e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 236/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7430e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00236: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 24s 197ms/step - loss: 8.7430e-05 - mean_absolute_error: 0.0074 - val_loss: 1.3746e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 237/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2441e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00237: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 24s 197ms/step - loss: 9.2441e-05 - mean_absolute_error: 0.0077 - val_loss: 5.7393e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 238/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7570e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00238: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 8.7570e-05 - mean_absolute_error: 0.0077 - val_loss: 2.4707e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 239/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1595e-05 - mean_absolute_error: 0.0072- ETA: 4s - loss: 7.9192e-05 -\n",
      "Epoch 00239: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 23s 188ms/step - loss: 8.1595e-05 - mean_absolute_error: 0.0072 - val_loss: 2.9016e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 240/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9943e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00240: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 7.9943e-05 - mean_absolute_error: 0.0074 - val_loss: 1.8676e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 241/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7165e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00241: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 151ms/step - loss: 8.7165e-05 - mean_absolute_error: 0.0075 - val_loss: 4.6105e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 242/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.3045e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00242: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 22s 175ms/step - loss: 9.3045e-05 - mean_absolute_error: 0.0077 - val_loss: 1.0384e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 243/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7661e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00243: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 7.7661e-05 - mean_absolute_error: 0.0074 - val_loss: 2.1589e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 244/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6542e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00244: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 153ms/step - loss: 7.6542e-05 - mean_absolute_error: 0.0074 - val_loss: 5.0571e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 245/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8081e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00245: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 7.8081e-05 - mean_absolute_error: 0.0072 - val_loss: 1.1641e-05 - val_mean_absolute_error: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7093e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00246: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 28s 223ms/step - loss: 7.7093e-05 - mean_absolute_error: 0.0072 - val_loss: 2.1712e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 247/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4256e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00247: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 8.4256e-05 - mean_absolute_error: 0.0072 - val_loss: 1.1924e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 248/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.6096e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00248: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 26s 208ms/step - loss: 9.6096e-05 - mean_absolute_error: 0.0079 - val_loss: 2.3047e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 249/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7936e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00249: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 23s 185ms/step - loss: 7.7936e-05 - mean_absolute_error: 0.0073 - val_loss: 1.4821e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 250/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5510e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00250: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 25s 203ms/step - loss: 8.5510e-05 - mean_absolute_error: 0.0075 - val_loss: 1.3356e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 251/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4702e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00251: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 155ms/step - loss: 8.4702e-05 - mean_absolute_error: 0.0075 - val_loss: 1.0504e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 252/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8614e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00252: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 125ms/step - loss: 7.8614e-05 - mean_absolute_error: 0.0072 - val_loss: 3.3404e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 253/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6181e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00253: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 173ms/step - loss: 7.6181e-05 - mean_absolute_error: 0.0073 - val_loss: 1.6884e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 254/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6703e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00254: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 8.6703e-05 - mean_absolute_error: 0.0075 - val_loss: 1.1398e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 255/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1678e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00255: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 8.1678e-05 - mean_absolute_error: 0.0073 - val_loss: 1.4523e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 256/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2464e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00256: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 8.2464e-05 - mean_absolute_error: 0.0073 - val_loss: 3.0034e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 257/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0403e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00257: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 8.0403e-05 - mean_absolute_error: 0.0074 - val_loss: 3.4053e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 258/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.2637e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00258: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 9.2637e-05 - mean_absolute_error: 0.0076 - val_loss: 2.4411e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 259/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0778e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00259: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 8.0778e-05 - mean_absolute_error: 0.0072 - val_loss: 8.6202e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 260/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.7217e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00260: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 152ms/step - loss: 9.7217e-05 - mean_absolute_error: 0.0080 - val_loss: 1.8334e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 261/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0332e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00261: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 8.0332e-05 - mean_absolute_error: 0.0073 - val_loss: 9.9986e-06 - val_mean_absolute_error: 0.0024\n",
      "Epoch 262/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2142e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00262: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 142ms/step - loss: 8.2142e-05 - mean_absolute_error: 0.0073 - val_loss: 1.8831e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 263/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6025e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00263: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 149ms/step - loss: 7.6025e-05 - mean_absolute_error: 0.0072 - val_loss: 2.7514e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 264/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0902e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00264: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 150ms/step - loss: 7.0902e-05 - mean_absolute_error: 0.0072 - val_loss: 2.1039e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 265/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9573e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00265: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 7.9573e-05 - mean_absolute_error: 0.0074 - val_loss: 4.0854e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 266/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4155e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00266: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 157ms/step - loss: 7.4155e-05 - mean_absolute_error: 0.0070 - val_loss: 1.6758e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 267/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9432e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00267: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 139ms/step - loss: 7.9432e-05 - mean_absolute_error: 0.0074 - val_loss: 2.4626e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 268/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0643e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00268: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 151ms/step - loss: 8.0643e-05 - mean_absolute_error: 0.0073 - val_loss: 1.7711e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 269/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.3221e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00269: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 8.3221e-05 - mean_absolute_error: 0.0072 - val_loss: 3.4319e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 270/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7663e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00270: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 8.7663e-05 - mean_absolute_error: 0.0076 - val_loss: 3.1915e-05 - val_mean_absolute_error: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.0477e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00271: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 9.0477e-05 - mean_absolute_error: 0.0078 - val_loss: 2.4826e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 272/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1393e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00272: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 153ms/step - loss: 8.1393e-05 - mean_absolute_error: 0.0072 - val_loss: 2.3854e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 273/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5350e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00273: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 8.5350e-05 - mean_absolute_error: 0.0076 - val_loss: 3.7487e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 274/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4414e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00274: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 169ms/step - loss: 7.4414e-05 - mean_absolute_error: 0.0071 - val_loss: 1.5424e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 275/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1609e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00275: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 7.1609e-05 - mean_absolute_error: 0.0071 - val_loss: 1.1297e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 276/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3650e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00276: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 7.3650e-05 - mean_absolute_error: 0.0071 - val_loss: 1.2307e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 277/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1548e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00277: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 8.1548e-05 - mean_absolute_error: 0.0073 - val_loss: 1.5416e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 278/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4149e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00278: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 156ms/step - loss: 8.4149e-05 - mean_absolute_error: 0.0075 - val_loss: 1.4902e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 279/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5203e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00279: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 25s 200ms/step - loss: 7.5203e-05 - mean_absolute_error: 0.0069 - val_loss: 1.8023e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 280/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1215e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00280: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 25s 204ms/step - loss: 8.1215e-05 - mean_absolute_error: 0.0071 - val_loss: 3.9197e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 281/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1213e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00281: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 150ms/step - loss: 8.1213e-05 - mean_absolute_error: 0.0072 - val_loss: 1.4196e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 282/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8328e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00282: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 137ms/step - loss: 7.8328e-05 - mean_absolute_error: 0.0072 - val_loss: 1.8224e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 283/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2353e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00283: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 122ms/step - loss: 8.2353e-05 - mean_absolute_error: 0.0073 - val_loss: 1.4520e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 284/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9492e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00284: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 7.9492e-05 - mean_absolute_error: 0.0073 - val_loss: 3.1317e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 285/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0893e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00285: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 7.0893e-05 - mean_absolute_error: 0.0070 - val_loss: 1.0551e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 286/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5119e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00286: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 122ms/step - loss: 8.5119e-05 - mean_absolute_error: 0.0075 - val_loss: 1.5311e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 287/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0553e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00287: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 8.0553e-05 - mean_absolute_error: 0.0071 - val_loss: 3.2610e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 288/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9504e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00288: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-19_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 7.9504e-05 - mean_absolute_error: 0.0072 - val_loss: 9.0705e-06 - val_mean_absolute_error: 0.0024\n",
      "Epoch 289/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6192e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00289: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 7.6192e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8512e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 290/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.8686e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00290: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 8.8686e-05 - mean_absolute_error: 0.0077 - val_loss: 2.1461e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 291/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4684e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00291: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 141ms/step - loss: 8.4684e-05 - mean_absolute_error: 0.0074 - val_loss: 1.5048e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 292/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3739e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00292: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 20s 160ms/step - loss: 7.3739e-05 - mean_absolute_error: 0.0071 - val_loss: 1.9614e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 293/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.6816e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00293: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 8.6816e-05 - mean_absolute_error: 0.0074 - val_loss: 4.1376e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 294/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.7937e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 00294: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 8.7937e-05 - mean_absolute_error: 0.0077 - val_loss: 2.5153e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 295/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8833e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00295: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 150ms/step - loss: 7.8833e-05 - mean_absolute_error: 0.0072 - val_loss: 2.2512e-05 - val_mean_absolute_error: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5811e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00296: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 8.5811e-05 - mean_absolute_error: 0.0075 - val_loss: 1.1513e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 297/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.8185e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00297: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 141ms/step - loss: 6.8185e-05 - mean_absolute_error: 0.0069 - val_loss: 1.2410e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 298/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5957e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00298: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 7.5957e-05 - mean_absolute_error: 0.0070 - val_loss: 1.1797e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 299/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7656e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00299: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 151ms/step - loss: 7.7656e-05 - mean_absolute_error: 0.0071 - val_loss: 1.6716e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 300/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8686e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00300: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 172ms/step - loss: 7.8686e-05 - mean_absolute_error: 0.0072 - val_loss: 1.2279e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 301/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7803e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00301: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 167ms/step - loss: 7.7803e-05 - mean_absolute_error: 0.0072 - val_loss: 4.3973e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 302/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6960e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00302: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 166ms/step - loss: 7.6960e-05 - mean_absolute_error: 0.0071 - val_loss: 1.2382e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 303/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7473e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00303: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 168ms/step - loss: 7.7473e-05 - mean_absolute_error: 0.0072 - val_loss: 9.7224e-06 - val_mean_absolute_error: 0.0022\n",
      "Epoch 304/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2882e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00304: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 22s 177ms/step - loss: 7.2882e-05 - mean_absolute_error: 0.0071 - val_loss: 2.9462e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 305/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4882e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00305: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 21s 168ms/step - loss: 7.4882e-05 - mean_absolute_error: 0.0070 - val_loss: 2.1126e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 306/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.8115e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00306: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 155ms/step - loss: 7.8115e-05 - mean_absolute_error: 0.0072 - val_loss: 3.2923e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 307/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.9162e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00307: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 6.9162e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9725e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 308/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3880e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00308: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 141ms/step - loss: 7.3880e-05 - mean_absolute_error: 0.0070 - val_loss: 9.1096e-06 - val_mean_absolute_error: 0.0023\n",
      "Epoch 309/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1089e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00309: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 139ms/step - loss: 7.1089e-05 - mean_absolute_error: 0.0070 - val_loss: 1.6016e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 310/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5945e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00310: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 8.5945e-05 - mean_absolute_error: 0.0074 - val_loss: 6.1386e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 311/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.1517e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00311: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 19s 149ms/step - loss: 9.1517e-05 - mean_absolute_error: 0.0076 - val_loss: 1.2645e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 312/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3521e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00312: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 7.3521e-05 - mean_absolute_error: 0.0070 - val_loss: 1.7510e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 313/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.6884e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00313: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 6.6884e-05 - mean_absolute_error: 0.0067 - val_loss: 1.8884e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 314/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4143e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00314: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 16s 133ms/step - loss: 7.4143e-05 - mean_absolute_error: 0.0070 - val_loss: 1.6203e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 315/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3986e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00315: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 137ms/step - loss: 7.3986e-05 - mean_absolute_error: 0.0069 - val_loss: 2.8498e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 316/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4570e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00316: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 136ms/step - loss: 7.4570e-05 - mean_absolute_error: 0.0071 - val_loss: 2.4068e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 317/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9472e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00317: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 133ms/step - loss: 7.9472e-05 - mean_absolute_error: 0.0071 - val_loss: 1.4086e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 318/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2167e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00318: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 17s 133ms/step - loss: 8.2167e-05 - mean_absolute_error: 0.0076 - val_loss: 1.8730e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 319/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 9.1750e-05 - mean_absolute_error: 0.0076\n",
      "Epoch 00319: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 9.1750e-05 - mean_absolute_error: 0.0076 - val_loss: 1.6421e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 320/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7006e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00320: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.7006e-05 - mean_absolute_error: 0.0072 - val_loss: 3.9717e-05 - val_mean_absolute_error: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2339e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00321: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.2339e-05 - mean_absolute_error: 0.0069 - val_loss: 2.5370e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 322/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9647e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00322: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.9647e-05 - mean_absolute_error: 0.0071 - val_loss: 1.6229e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 323/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5943e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00323: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.5943e-05 - mean_absolute_error: 0.0071 - val_loss: 5.1140e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 324/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.2463e-05 - mean_absolute_error: 0.0074\n",
      "Epoch 00324: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 8.2463e-05 - mean_absolute_error: 0.0074 - val_loss: 1.4531e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 325/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9969e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00325: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.9969e-05 - mean_absolute_error: 0.0072 - val_loss: 3.1827e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 326/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.5375e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00326: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.5375e-05 - mean_absolute_error: 0.0075 - val_loss: 3.3170e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 327/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.1422e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00327: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 8.1422e-05 - mean_absolute_error: 0.0073 - val_loss: 4.0014e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 328/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1667e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00328: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1667e-05 - mean_absolute_error: 0.0068 - val_loss: 9.2528e-06 - val_mean_absolute_error: 0.0025\n",
      "Epoch 329/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5034e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00329: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 114ms/step - loss: 7.5034e-05 - mean_absolute_error: 0.0071 - val_loss: 1.4301e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 330/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.5427e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00330: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.5427e-05 - mean_absolute_error: 0.0069 - val_loss: 2.0479e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 331/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2813e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00331: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.2813e-05 - mean_absolute_error: 0.0069 - val_loss: 1.1278e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 332/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0191e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00332: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.0191e-05 - mean_absolute_error: 0.0068 - val_loss: 1.2343e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 333/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1276e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00333: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1276e-05 - mean_absolute_error: 0.0069 - val_loss: 2.8244e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 334/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3728e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00334: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.3728e-05 - mean_absolute_error: 0.0070 - val_loss: 5.7945e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 335/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9814e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00335: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.9814e-05 - mean_absolute_error: 0.0072 - val_loss: 1.1229e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 336/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0235e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00336: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 7.0235e-05 - mean_absolute_error: 0.0068 - val_loss: 1.0320e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 337/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0797e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00337: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.0797e-05 - mean_absolute_error: 0.0071 - val_loss: 1.4019e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 338/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.9659e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00338: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.9659e-05 - mean_absolute_error: 0.0069 - val_loss: 1.4862e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 339/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7706e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00339: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.7706e-05 - mean_absolute_error: 0.0069 - val_loss: 2.1370e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 340/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5056e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00340: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.5056e-05 - mean_absolute_error: 0.0071 - val_loss: 1.3144e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 341/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2530e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00341: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.2530e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4209e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 342/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0751e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00342: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.0751e-05 - mean_absolute_error: 0.0070 - val_loss: 1.6130e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 343/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0125e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00343: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.0125e-05 - mean_absolute_error: 0.0072 - val_loss: 1.4869e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 344/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1649e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00344: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1649e-05 - mean_absolute_error: 0.0067 - val_loss: 9.1229e-06 - val_mean_absolute_error: 0.0020\n",
      "Epoch 345/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2125e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00345: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.2125e-05 - mean_absolute_error: 0.0068 - val_loss: 1.1422e-05 - val_mean_absolute_error: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0049e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00346: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.0049e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4244e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 347/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6592e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00347: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.6592e-05 - mean_absolute_error: 0.0071 - val_loss: 1.3708e-05 - val_mean_absolute_error: 0.0021\n",
      "Epoch 348/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.9953e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00348: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 105ms/step - loss: 6.9953e-05 - mean_absolute_error: 0.0069 - val_loss: 1.3584e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 349/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.7497e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00349: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.7497e-05 - mean_absolute_error: 0.0067 - val_loss: 3.4372e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 350/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6052e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00350: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.6052e-05 - mean_absolute_error: 0.0070 - val_loss: 3.0298e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 351/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.8172e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00351: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.8172e-05 - mean_absolute_error: 0.0067 - val_loss: 1.3822e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 352/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0468e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00352: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.0468e-05 - mean_absolute_error: 0.0070 - val_loss: 1.1847e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 353/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5157e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00353: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.5157e-05 - mean_absolute_error: 0.0068 - val_loss: 2.1925e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 354/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0923e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00354: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 8.0923e-05 - mean_absolute_error: 0.0072 - val_loss: 1.5821e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 355/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.6844e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00355: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 6.6844e-05 - mean_absolute_error: 0.0070 - val_loss: 1.1441e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 356/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9426e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00356: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.9426e-05 - mean_absolute_error: 0.0073 - val_loss: 2.0699e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 357/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9003e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00357: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.9003e-05 - mean_absolute_error: 0.0073 - val_loss: 1.6797e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 358/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.7551e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00358: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 6.7551e-05 - mean_absolute_error: 0.0068 - val_loss: 3.4251e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 359/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2948e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00359: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.2948e-05 - mean_absolute_error: 0.0070 - val_loss: 9.5138e-05 - val_mean_absolute_error: 0.0087\n",
      "Epoch 360/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.8392e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00360: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.8392e-05 - mean_absolute_error: 0.0068 - val_loss: 1.3178e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 361/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.7546e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00361: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.7546e-05 - mean_absolute_error: 0.0067 - val_loss: 1.3125e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 362/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1752e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00362: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1752e-05 - mean_absolute_error: 0.0068 - val_loss: 1.2780e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 363/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0963e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00363: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.0963e-05 - mean_absolute_error: 0.0069 - val_loss: 1.9124e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 364/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1707e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00364: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1707e-05 - mean_absolute_error: 0.0068 - val_loss: 2.1297e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 365/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.4896e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00365: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.4896e-05 - mean_absolute_error: 0.0069 - val_loss: 1.5516e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 366/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.9553e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00366: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.9553e-05 - mean_absolute_error: 0.0069 - val_loss: 2.3849e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 367/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1415e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00367: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.1415e-05 - mean_absolute_error: 0.0067 - val_loss: 4.1204e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 368/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.9986e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00368: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 6.9986e-05 - mean_absolute_error: 0.0069 - val_loss: 1.5198e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 369/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1848e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00369: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1848e-05 - mean_absolute_error: 0.0068 - val_loss: 1.6087e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 370/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.7066e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00370: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.7066e-05 - mean_absolute_error: 0.0067 - val_loss: 2.1192e-05 - val_mean_absolute_error: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3937e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00371: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.3937e-05 - mean_absolute_error: 0.0070 - val_loss: 1.3797e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 372/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.7805e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00372: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.7805e-05 - mean_absolute_error: 0.0068 - val_loss: 1.3900e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 373/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.6548e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00373: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 7.6548e-05 - mean_absolute_error: 0.0072 - val_loss: 3.6915e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 374/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1029e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00374: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 112ms/step - loss: 7.1029e-05 - mean_absolute_error: 0.0068 - val_loss: 2.6678e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 375/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1567e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00375: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.1567e-05 - mean_absolute_error: 0.0070 - val_loss: 3.2184e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 376/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2511e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00376: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.2511e-05 - mean_absolute_error: 0.0069 - val_loss: 6.3422e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 377/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5944e-05 - mean_absolute_error: 0.0072\n",
      "Epoch 00377: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.5944e-05 - mean_absolute_error: 0.0072 - val_loss: 1.1073e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 378/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3941e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00378: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.3941e-05 - mean_absolute_error: 0.0069 - val_loss: 1.2553e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 379/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.4251e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00379: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 6.4251e-05 - mean_absolute_error: 0.0067 - val_loss: 2.0904e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 380/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3121e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00380: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.3121e-05 - mean_absolute_error: 0.0069 - val_loss: 2.6224e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 381/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7470e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00381: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 7.7470e-05 - mean_absolute_error: 0.0071 - val_loss: 1.7152e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 382/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9487e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00382: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 7.9487e-05 - mean_absolute_error: 0.0073 - val_loss: 2.4116e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 383/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5517e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00383: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 108ms/step - loss: 7.5517e-05 - mean_absolute_error: 0.0070 - val_loss: 1.0821e-05 - val_mean_absolute_error: 0.0024\n",
      "Epoch 384/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.7939e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 00384: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.7939e-05 - mean_absolute_error: 0.0071 - val_loss: 1.2051e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 385/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.0625e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00385: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.0625e-05 - mean_absolute_error: 0.0067 - val_loss: 1.3254e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 386/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3101e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00386: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.3101e-05 - mean_absolute_error: 0.0068 - val_loss: 2.5304e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 387/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1738e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00387: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.1738e-05 - mean_absolute_error: 0.0070 - val_loss: 3.5504e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 388/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4086e-05 - mean_absolute_error: 0.0073\n",
      "Epoch 00388: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.4086e-05 - mean_absolute_error: 0.0073 - val_loss: 1.2149e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 389/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.0181e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00389: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 8.0181e-05 - mean_absolute_error: 0.0070 - val_loss: 2.1103e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 390/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.5456e-05 - mean_absolute_error: 0.0067\n",
      "Epoch 00390: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.5456e-05 - mean_absolute_error: 0.0067 - val_loss: 2.2817e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 391/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.9103e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00391: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 105ms/step - loss: 6.9103e-05 - mean_absolute_error: 0.0069 - val_loss: 1.1000e-05 - val_mean_absolute_error: 0.0023\n",
      "Epoch 392/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.3666e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00392: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.3666e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4190e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 393/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.5388e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00393: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.5388e-05 - mean_absolute_error: 0.0070 - val_loss: 2.6073e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 394/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.8651e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00394: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 6.8651e-05 - mean_absolute_error: 0.0069 - val_loss: 1.5258e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 395/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.9010e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00395: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.9010e-05 - mean_absolute_error: 0.0069 - val_loss: 2.9250e-05 - val_mean_absolute_error: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1783e-05 - mean_absolute_error: 0.0070\n",
      "Epoch 00396: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1783e-05 - mean_absolute_error: 0.0070 - val_loss: 3.6645e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 397/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.6473e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00397: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 6.6473e-05 - mean_absolute_error: 0.0069 - val_loss: 1.1371e-05 - val_mean_absolute_error: 0.0022\n",
      "Epoch 398/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.1367e-05 - mean_absolute_error: 0.0070- ETA: 2s - loss: 6.9283e-05 - mean\n",
      "Epoch 00398: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 7.1367e-05 - mean_absolute_error: 0.0070 - val_loss: 1.6135e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 399/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 7.2139e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 00399: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 7.2139e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7773e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 400/400\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.7956e-05 - mean_absolute_error: 0.0068\n",
      "Epoch 00400: val_loss did not improve from 0.00001\n",
      "124/124 [==============================] - 13s 107ms/step - loss: 6.7956e-05 - mean_absolute_error: 0.0068 - val_loss: 9.8904e-06 - val_mean_absolute_error: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard,es],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
    "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.424268679294879\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data, classification=False):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
    "    # retrieve the column scalers\n",
    "    column_scaler = data[\"column_scaler\"]\n",
    "    # reshape the last sequence\n",
    "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 1 days is 398.45$\n"
     ]
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(model, data):\n",
    "    y_test = data[\"y_test\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    # last 200 days, feel free to edit that\n",
    "    plt.plot(y_test[-200:], c='b')\n",
    "    plt.plot(y_pred[-200:], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTMs to predict the closing stock price of Apple Inc. (Using past 60 days data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>111.440002</td>\n",
       "      <td>107.349998</td>\n",
       "      <td>111.389999</td>\n",
       "      <td>109.330002</td>\n",
       "      <td>53204600.0</td>\n",
       "      <td>99.945885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>108.650002</td>\n",
       "      <td>105.410004</td>\n",
       "      <td>108.290001</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>64285500.0</td>\n",
       "      <td>97.130241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>107.430000</td>\n",
       "      <td>104.629997</td>\n",
       "      <td>106.540001</td>\n",
       "      <td>106.260002</td>\n",
       "      <td>65797100.0</td>\n",
       "      <td>97.139420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>108.199997</td>\n",
       "      <td>106.699997</td>\n",
       "      <td>107.199997</td>\n",
       "      <td>107.750000</td>\n",
       "      <td>40105900.0</td>\n",
       "      <td>98.501518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>112.150002</td>\n",
       "      <td>108.699997</td>\n",
       "      <td>109.230003</td>\n",
       "      <td>111.889999</td>\n",
       "      <td>59364500.0</td>\n",
       "      <td>102.286186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close      Volume  \\\n",
       "Date                                                                     \n",
       "2015-01-02  111.440002  107.349998  111.389999  109.330002  53204600.0   \n",
       "2015-01-05  108.650002  105.410004  108.290001  106.250000  64285500.0   \n",
       "2015-01-06  107.430000  104.629997  106.540001  106.260002  65797100.0   \n",
       "2015-01-07  108.199997  106.699997  107.199997  107.750000  40105900.0   \n",
       "2015-01-08  112.150002  108.699997  109.230003  111.889999  59364500.0   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2015-01-02   99.945885  \n",
       "2015-01-05   97.130241  \n",
       "2015-01-06   97.139420  \n",
       "2015-01-07   98.501518  \n",
       "2015-01-08  102.286186  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data from 1 Jan 2015 to 01 Aug 2020\n",
    "df = web.DataReader('AAPL', data_source='yahoo', start = '2015-01-01',end='2020-08-01')\n",
    "# exploring data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1405, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring closing price history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Price(USD)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCwAAAIdCAYAAAD25OyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXQUZfr28auzh2wdQhLWBJC4ECIgGBlEFkEUkIgCggsw48JPfD0yorK4oQ6CuKCAgDgiiiKgqKDiAKLswyYuiApGVEDAJASy70m/fzBp6SVJN+lOd8L3c45n7Krqqqea8pypi/u5H0NWVpZJAAAAAAAAXsTH0wMAAAAAAACwRmABAAAAAAC8DoEFAAAAAADwOgQWAAAAAADA6xBYAAAAAAAAr0NgAQAAAAAAvA6BBQCgQTt8+LCMRqPGjRtXZ9ccNGiQjEZjnV2vIZkxY4aMRqOWLl3q6aHY8MSzVJ3K5+zw4cMOfycpKUlJSUluHBUAAK5DYAEAqHdSU1M1adIkde/eXXFxcYqOjtaFF16oYcOG6Y033lB+fr6nh1ivJSUlEbjALqPRSOABAKgzfp4eAAAAznjuuef07LPPqqKiQl27dtXIkSMVFham9PR0/fe//9WECRM0d+5cffPNNx4b46uvvqrCwkKPXR/u0bx5c+3evVvh4eGeHso5+/jjjz09BAAAHEZgAQCoN1588UVNnz5dLVq00OLFi5WcnGxzzMaNGzVt2jQPjO4vrVq18uj14R7+/v668MILPT2MWmnTpo2nhwAAgMOYEgIAqBcOHz6sZ599Vv7+/lqxYoXdsEKS+vTpo88++8yhc6anp2vixInq2LGjYmJi1KZNG40YMULbt2+3OdZkMmnZsmW69tpr1a5dO8XGxqp9+/YaPHiw3nrrLYtj7fWw2Lp1q7n/weHDh3XHHXeobdu2io2NVe/evbV27Vq7Y8zOztbkyZPVvn17xcbG6vLLL9crr7yi33//3al+Co6Mv7JHw9GjRyWdKf+v/GfQoEEW59u3b5/+/ve/KyEhQdHR0UpMTNR9992n33//3e71y8vL9eabb2rAgAGKi4tT06ZN1bFjR91zzz368ccfaxx/dna2UlJSZDQa9cwzz9R4/NKlS2U0GjVjxgzt3LlTKSkpatWqlVq1aqVhw4bp22+/tfnO2f0z1q9frwEDBqhVq1aKj4+3+H3s/eaFhYWaM2eO+vTpo5YtW6p58+bq2rWrHnzwQfPvWamoqEhz585Vr1691KJFCzVv3ly9e/fWG2+8IZPJVOO92bN48WJ1795dsbGxSkhI0Pjx45WdnW1znL0eFiUlJVq4cKF69eqlNm3aqGnTpurQoYOGDRtmrsiofH4l6ejRoxbPhvXvsXXrVt18881q06aNYmJi1LFjR02ePFknT560Gc+4ceNkNBq1detWLV++XH369FHz5s3Vo0cPffHFFzIajbr33nvt3nN5ebnat2+vFi1a2L1XAED9R4UFAKBeWLp0qUpLS3XTTTepQ4cO1R4bGBhY4/mOHDmiAQMG6NixY7ryyit100036c8//9SqVav0+eefa+7cubrtttvMx//rX//SrFmzFBcXpxtuuEERERFKS0vT/v37tXz5co0ZM8ah+zh69Kj69u2r1q1ba8SIETp9+rQ++ugj3XrrrVq1apV69uxpPraoqEgpKSn67rvv1KFDBw0fPlw5OTl68cUXtWPHDoeu58z4IyIiNGnSJC1YsEA5OTmaNGmS+ftxcXHmf//88891++23q7y8XIMHD1abNm30ww8/6J133tGnn36qjz/+WJdeeqn5+JKSEo0YMUIbN25UixYtNHToUEVEROiPP/7QF198oUsvvVTt27evcuzHjh3T8OHD9fPPP2vOnDkaPXq0w/e9d+9evfTSS+rTp4/uvvtuHTp0SJ988om2b9+uVatW6YorrrD5zurVq/XFF1+of//+uuOOO5Senl7tNbKysjR48GB9//33ateunW699VYFBQXp999/1/vvv68+ffqYq25yc3M1ZMgQ7d27V5deeqluvfVWSdIXX3yhCRMmaM+ePVqwYIHD9ydJU6dO1ZdffqnrrrtOffr00datW/XWW2/p119/1SeffFLj9++9916tXLlSF198sYYPH66QkBCdOHFCX3/9tT799FOlpKQoLi5OkyZN0syZMxUeHm4RUpwdgCxZskTjx49XcHCwbrjhBjVt2lS7du3Sq6++qk8//VTr1q1TixYtbMbwyiuvaPPmzRowYIB69eqlkpISXX311WrTpo0++ugjTZ8+3SYEXLt2rY4fP65Ro0YpIiLCqd8MAFA/EFgAAOqFnTt3SpJ69+7tkvNNmDBBx44d0+TJkzV58mTz9vvuu0/9+vXThAkT1Lt3b/PL1eLFi9WsWTPt2LFDISEhFufKzMx0+Lrbtm2zuebw4cM1dOhQzZ071yKwmDNnjr777jvdcMMNWrx4sXx8zhRGPvjgg+rVq5dT9+vI+I1Go6ZMmaJ3331XOTk5mjJlis158vPzdc8996i0tNQmYFmyZInuv/9+3XPPPdq+fbsMBoMk6dlnn9XGjRvVv39/LVmyREFBQebvlJaW6vTp01WOe//+/br55puVnZ2tZcuW6ZprrnHqvjds2KDnn39ed999t3nb6tWrNWbMGN13333avXu3eZyVPv/8c73//vvq16+fQ9d46KGH9P3332v06NF6+eWXzX9OklRQUKDi4mLz50ceeUR79+7Vk08+qX/+85/m7cXFxRo1apSWLVumlJQUDRgwwOF7/Oqrr7R9+3ZzKFJWVqbBgwdr69at2rt3r7p06VLld7Ozs/XBBx+oU6dO2rBhg/z8LP+vYeWzER8frylTpmjmzJmKiIiw+2z88ccfeuihh9SoUSNt2LBBl1xyiXnftGnT9MILL2jChAlasWKFzXe3bt2q9evXWwRdknTHHXfo8ccf1/Lly3XPPfdY7Fu8eLH5GABAw8SUEABAvZCWlibpTOPD2jp+/Lg2bNigFi1aaMKECRb7EhMTdccdd6i4uNjmxcrf39/mhU6SoqKiHL52q1at9PDDD1ts69u3r1q2bKm9e/dabF+2bJkMBoOefPJJi5fgli1bntPSmq4Y/5o1a5SZmamUlBSLsEKSRo8erY4dO+rHH3/Unj17JJ0p23/99dcVFBSkWbNmWYQVlWOKiYmxe61NmzZp4MCBKisr05o1a5wOKySpbdu2uvPOOy223XDDDUpOTlZqaqp27dpl852BAwc6HFZkZGToww8/VExMjKZPn27x5yRJjRo1UmRkpCTp9OnTWrZsmS699FKLsEI6UxX0xBNPSJLdF/rqTJw40aJvip+fn7k6yPqZsmYwGGQymRQQECBfX1+b/c48G8uXL1dJSYnuvPNOi7BCOhPqNGvWTOvWrdOJEydsvjtmzBibsEKSbr/9dgUFBenNN9+02H748GF9+eWX6tSpkzp37uzwGAEA9QuBBQDgvPPdd99Jkq644goFBATY7K+s4qg8TjpTBXHkyBElJydr6tSpWrt2bbWVAVVJSkqy+2LYsmVLZWVlmT/n5OTot99+U2xsrN1Gid26dXPquq4af+VvYh1WVLL+7X7++Wfl5OTo4osvVsuWLR2+zscff6zhw4crNjZW69evV6dOnZweqyT97W9/swkRJOnKK6+UdKYXh7XqKhKsff3116qoqFC3bt0UGhpa7bF79+5VWVmZfHx8NGPGDJt/PvroI0lnfjNn2PttKn/rs58pe8LDw3Xddddp9+7duvLKKzV9+nRt3LhReXl5To1Bqv7ZCAoKMj+zzvzmkZGRuvHGG3XgwAGLaVBLlixRRUUF1RUA0MAxJQQAUC/Exsbq4MGDOn78eK3PlZOTI0lV/s1+bGysJFk08psxY4batm2rd999V3PmzNHs2bPl4+OjXr166emnn7ZpZFiVquba+/r6qqKiwvw5NzdXkhQdHW33+KrGXhVXjd/Z367yf5s1a+bUeHfv3q3S0lJddtllFv0znFXVOCt/18r7ceQ79jhzf6dOnZIkffvtt3abflZyNiyw90xVhmLl5eU1fn/x4sWaM2eOVq5cqeeee07SmcqX6667TtOmTTM3Ha3Jufx3Vam63/yuu+7SsmXLtHjxYv3tb39TaWmp3nnnHYWHh2vo0KEOjQ0AUD9RYQEAqBcq/3Z28+bNtT5XeHi4JFXZTLFy+knlcdKZF8B77rlHW7Zs0aFDh/Tuu+/q5ptv1qZNm3TjjTeaX0ZdJSwsTNKZKQf21NQI0pqrxu/sb1f5Mm1vGkB1nnjiCQ0cOFArVqzQPffc49CLtz1VjbPydz37z7iSdU+L6jhzf5XXGjt2rLKysqr8x14FgjsFBwdr0qRJ2rNnj3766Se98cYb6tevnz755BMNGzZMpaWlDp3nXP67qlTdb96lSxd16tRJq1ev1qlTp/TZZ58pLS1NI0aMsOnHAgBoWAgsAAD1wm233SZ/f399/PHHNS6DeXaTQ3sq58rv2rVLJSUlNvsrQ5GqpiE0btxYAwcO1KuvvqqhQ4fq5MmTTq/aUZPw8HC1bt1aaWlp+u2332z2VzYhPRc1jb+6v53v2LGjpDNNEu3ZsmWLpL9+uwsvvFARERE6cOCA/vjjD4fHGBAQoCVLluimm27Se++9pzvuuMPhF+ez7dy506JypVLl0rX2+iY4o0uXLvLx8dHOnTtrrIzo2rWrfHx8XP6suFKzZs100003admyZeY+HwcOHDDv9/Hxsft7StU/G8XFxeZ+IZXHOePOO+9UcXGx3n33XXOzzX/84x9OnwcAUL8QWAAA6oX4+HhNnjxZpaWluvnmm/XVV1/ZPW7Lli26/vrrqz1XixYt1LdvXx07dkyzZ8+22Ff5N8yBgYG6+eabJZ152bL3kmkymcx/U9+oUaNzua1qjRw5UiaTSU899ZTFS+KxY8ecWvrS2fE3btxY0pklWK0NGjRIjRs31urVq80v/ZWWLl2qb775Rpdccokuv/xySWfCj7vuuktFRUWaMGGCTZhUVlZW5d/I+/n56d///rduvfVWrV69WrfffnuNYZS1Q4cOadGiRRbbVq9erd27dyshIcHusqbOaNKkiYYOHar09HQ9+uijNi/zhYWF5l4hTZo00YgRI/T9999rxowZKisrsznfsWPHnO5hURsnT57U/v37bbYXFxebp25YPxsnT55UYWGhzXduvvlmBQQEaNGiRTb3MGvWLB0/flz9+/d3enqQJA0bNkxGo1Hz5s3T5s2b1a1bt2qXwgUANAz0sAAA1BsPPvigysrKNHPmTPXr10/Jycnq3LmzwsLClJGRoZ07d+rgwYO64IILajzXrFmzdN111+mZZ57Rli1bdPnll+vPP//UqlWrVFRUpJdfftncuLCwsFADBgxQ69at1blzZ7Vq1UqlpaXatm2bvv/+e11++eW66qqrXH6/48eP15o1a7Rq1SodOnRIV199tXJzc/XRRx+pe/fuWrNmjd2GktacHX+fPn309ddfa9SoUerfv7+CgoLUqlUrjRw5UiEhIZo/f75Gjx6tIUOGKCUlRa1bt9b+/fu1fv16RUREaMGCBRYl/pMmTdLevXu1fv16XXbZZbruuusUHh6uY8eOafPmzRo/frzuvfdeu2P39fXVvHnzFBwcrEWLFmnkyJFaunSpwwFR37599eijj2rDhg1KTEzUoUOH9Mknnyg4OFhz5851avpHVZ5//nn99NNPeuutt7R9+3b17dtXQUFBOnLkiL788kvNmzfPHKI999xz+vXXXzVz5kytWLFC3bt3V2xsrNLS0vTLL79oz549euaZZ3ThhRfWelyOOH78uHr27Kn27dsrMTFRLVq0UH5+vr788ksdOnRIKSkpFv899enTR++//76GDh2q7t27KzAwUB06dNCAAQMUFxenmTNnasKECerTp4+GDBmi2NhY7dq1S9u3b1eLFi304osvntM4g4ODdeutt2r+/PmSqK4AgPMFgQUAoF6ZNGmSbrzxRr3++uvatm2bli1bpoKCAkVGRqpDhw4aO3asbrnllhrPEx8fr02bNumFF17Q2rVrtXPnToWEhOjKK6/U/fffb/ECHxISoqefflpbt27Vnj179J///EfBwcGKj4/XtGnT9I9//MPucqG1FRwcrE8++UTTp0/Xxx9/rAULFig+Pl4TJkwwBxaVvS6q4+z4H3zwQeXk5Og///mPZs+erbKyMl155ZUaOXKkJOm6667T+vXrNWvWLG3evFmrV69WdHS0brnlFk2cOFGtW7e2uH5AQIBWrlypN998U8uXL9eKFStUXl6u2NhY9e3bV3369Kl2/AaDQS+++KKCgoI0b948DRs2TCtWrHDo3rt27aqHH35YzzzzjF577TVJZ166H3/88XNeecSa0WjU+vXr9eqrr+rDDz/UkiVL5OPjo+bNm2v48OEW1wkLC9Onn36qt99+W++//74+/fRTFRUVKTo6WvHx8Zo6dapuvPFGl4zLEXFxcXrkkUe0detWbd++XSdPnlRERITatm2r8ePH69Zbb7U4fsaMGfLx8dGmTZvM021uueUWDRgwQNKZIKFt27aaO3eu1qxZo/z8fDVr1kxjx47VQw895HSz2LONGjVK8+fPV+PGjTVkyJBa3TcAoH4wZGVlmTw9CAAA4Jy33npL48eP10svvcTfNtuxdOlS/b//9/80adIkTZkyxdPDgQusXLlSd911l+677z5NmzbN08MBANQBelgAAODF7K0+cfToUT3//PPy8/PTdddd54FRAXWrvLxcc+fOlY+Pj+666y5PDwcAUEeYEgIAgBe74447VFhYqE6dOikiIkJHjhzRunXrVFBQoKlTp55TA0OgvtixY4e2b9+u7du367vvvtPo0aNtphwBABouAgsAALzY8OHDtXz5cn388cfKyclRSEiIunTporvvvlspKSmeHh7gVps2bdLMmTNlNBp12223acaMGZ4eEgCgDtHDAgAAAAAAeB16WAAAAAAAAK9DYAEAAAAAALwOgQUAAAAAAPA6BBZeLjU11dNDAMx4HuEteBbhTXge4S14FuEteBbhKgQWAAAAAADA6xBYAAAAAAAAr0NgAQAAAAAAvA6BBQAAAAAA8DoEFgAAAAAAwOsQWAAAAAAAAK9DYAEAAAAAALwOgQUAAAAAAPA6BBYAAAAAAMDrEFgAAAAAAACvQ2ABAAAAAAC8DoEFAAAAAADwOgQWAAAAAADA6xBYAAAAAAAAr0NgAQAAAAAAvA6BBQAAAAAA8DoEFgAAAAAAwOv4eXoAAAAAAADg3JRXmJRbapLBIPkYJD+DQcF+Bk8PyyUILAAAAAAAqKf+yC9Xx5Vp5s+tQn31/fCmHhyR6zAlBAAAAACAespk9bkhveQ3pHsBAAAAAOC8UmGVWPg0jNkgkggsAAAAAACot8pNlokFgQUAAAAAAPA42wqLhpNYEFgAAAAAAFBPWQcWvg0nryCwAAAAAACgvrKpsPDMMNyiId0LAAAAAADnFeseFg1oRgiBBQAAAAAA9RU9LAAAAAAAgNexyivoYQEAAAAAADzPtsLCM+NwBwILAAAAAADqKQILAAAAAADgdaybbvqo4SQWBBYAAAAAANRT1hUWvg3oLb8B3QoAAAAAAOeXCqvPDae+gsACAAAAAIB6ix4WAAAAAADA61RY97AwNJzEgsACAAAAAIB6igoLAAAAAADgdWyabhJYAAAAAAAAT7OpsPDMMNyiId0LAAAAAADnlXKbHhYeGogbEFgAAAAAAFBPWVdYGGi6CQAAAAAAPK3C6jM9LAAAAAAAgMexSggAAAAAAPA6FfSwAAAAAAAA3sZ2lZCGk1gQWAAAAAAAUE9ZBxa+DegtvwHdCgAAAAAA5xfrppsN6SXfa+5l1qxZMhqNevjhh83bTCaTZsyYoYsvvlhNmzbVoEGD9NNPP1l8LysrS2PHjlVcXJzi4uI0duxYZWVl1fXwAQAAAACoc+VWJRYNaFVT7wgs9uzZozfffFOJiYkW22fPnq158+Zp5syZ+vLLLxUdHa0bb7xRubm55mPuuusu7du3TytXrtTKlSu1b98+/d///V9d3wIAAAAAAHXOpsKiASUWHg8ssrOzdffdd+uVV16R0Wg0bzeZTFqwYIH++c9/6oYbblD79u21YMEC5eXlaeXKlZKkgwcPasOGDXr55ZeVnJys5ORkvfTSS1q3bp1SU1M9dUsAAAAAANQJljV1o8pAomfPnhbbDx8+rLS0NF199dXmbcHBwerevbt27dolSdq9e7dCQ0N1xRVXmI/p1q2bQkJCzMcAAAAAANBQmaybbjagwMLPkxd/66239Ouvv+q1116z2ZeWliZJio6OttgeHR2tEydOSJLS09MVFRUlw1klLwaDQU2aNFF6enqV161v1Rf1bbxo2Hge4S14FuFNeB7hLXgW4S14FuvOn2l+kgLMn3NzspWaetJzA3JCQkJCtfs9Flikpqbq6aef1tq1a+Xv71+n167pR/Emqamp9Wq8aNh4HuEteBbhTXge4S14FuEteBbrVlRZnnQo2/w5MsKohARjNd+oPzw2JWT37t3KzMxUt27dFBUVpaioKG3fvl2vv/66oqKi1LhxY0lSRkaGxfcyMjIUExMjSYqJiVFmZqZMZ9XAmEwmnTx50nwMAAAAAAANFT0s3GDQoEH673//q61bt5r/6dy5s4YOHaqtW7eqXbt2io2N1caNG83fKSoq0o4dO8w9K5KTk5WXl6fdu3ebj9m9e7fy8/Mt+loAAAAAANAQ2a4S4pFhuIXHpoQYjUaLVUEkqVGjRoqMjFT79u0lSePGjdOsWbOUkJCgdu3a6YUXXlBISIiGDRsmSbrooovUr18/PfDAA3r55ZclSQ888ICuvfZaSpAAAAAAAA1eQ66w8GjTzZqMHz9ehYWFevjhh5WVlaUuXbroww8/VFhYmPmY119/XRMnTtTQoUMlSQMGDNBzzz3nqSEDAAAAAFBnyq2WCSGwcJM1a9ZYfDYYDJoyZYqmTJlS5XeMRqPdVUYAAAAAAGhoPv+jSA/vzJK/j0FzrjTaLGvqo4aTWHishwUAAAAAAHBceYVJ928/rd9zy5WaXaaHdmTZTAnxbTh5BYEFAAAAAAD1wdH8cp0o+KvN5g+ny1TWgHtYEFgAAAAAAODlvjhWpB6r0m22ZxVbrhPSkAILr+phAQAAAAAALGUUluvWLzJVXG6775RVYGEwNJzEggoLAAAAAAC82OKD+XbDCsk2sGhIFRYEFgAAAAAAeLGfs8uq3Lf2aJHFZ5puAgAAAACAOpFtVUVRnYb0kt+Q7gUAAAAAgAYnz3opkGr40MMCAAAAAADUhdIKZwILNw6kjhFYAAAAAADgxfJKHQ8s6GEBAAAAAADqRE6J4z0sGtCMEAILAAAAAAC81bqjRTpe4ETTzQaUWBBYAAAAAADghdYfLdKIDZlOfSe4Ac0JIbAAAAAAAMALPfNNjtPfiQpqOK/5DedOAAAAAABoIE4Vleu7zFK7+6pbCaRxYMN5zW84dwIAAAAAQAPx9Un7YcUlRj8FVPMmT4UFAAAAAABwm99zy+xuHxQfLP9qSiyiqLAAAAAAAADuUlBmstk2u7tRUzqFya+aN/nIBhRY+Hl6AAAAAAAAwFK+VWAxsVOYxlwUIkn/q7CwDTT8DFIAq4QAAAAAAAB3KbQKLBqdFUT4G+yHEnaKMuo1AgsAAAAAALyM9ZSQYL+/QorqpoQ0JOfJbQIAAAAAUH9YBxaNzgosqmu62ZAQWAAAAAAA4GWqDyzqejSecZ7cJgAAAAAA9UdhWYXFZ8spIVRYAAAAAACAOmYymbTuj2KLbSFUWAAAAAAAAE/ak1Fisy2YHhYAAAAAAMCTvjxWbLMt0LfmVUKCfRtWkEFgAQAAAACAFzldXGGzrVkjX/O/V1VhMbeH0W1j8gQCCwAAAAAAvMivOWUWn0P8DIoJ/iuwyC+1DTTGdwhVSnyw28dWl/w8PQAAAAAAAPCXQ1aBxWcDm1h8DrIz9eOpyyPcOiZPoMICAAAAAAAvUVph0uG8cottF4Rb1ho8clm4xefhbRtWZUUlAgsAAAAAALzEkdxylZv++tw02EehVuuY/i02UA8khSrAR0qI8NODHcPqeJR1gykhAAAAAAB4iV+spoO0Dbf/2j61a4SmdA6Xr0HybaDLnFJhAQAAAACAh2w6XqSrP0nXTetO6lB2mU3/inYRVdcZBPgaGmxYIVFhAQAAAACAR5RWmHTX5tM6WXRm1Y9HdmepVajla7p1/4rzyfl75wAAAAAAeND+U6XmsEKS1v1RLKnY4piqpoScD5gSAgAAAACAB5RWmGo85nyusCCwAAAAAADAAxzIK9QmjMACAAAAAADUoYKy6hOLhAg/Bfs13KaaNSGwAAAAAADAA/JKqw8sHr8svI5G4p0ILAAAAAAA8ID8aioshrQOVkrr4DocjfchsAAAAAAAwAMKyiqq3Hex8fztXVGJwAIAAAAAAA/Ir2ZKSFyobx2OxDsRWAAAAAAA4AF51UwJiTuPVwepRGABAAAAAIAH5JVWPSUkngoLAgsAAAAAADzhz4KqA4tmjQgsCCwAAAAAAPCAP/LK7W4PDzDIz8dQx6PxPgQWAAAAAAB4wB/5ZXa3Nw2mukIisAAAAAAAoM6VVpj0Z6H9KSExwbyqSwQWAAAAAADUuRMF5aqoYpGQWCosJEmskwIAAAAAgJuVVZj07i8FKigzaVRCoyr7V0hSbCNqCyQCCwAAAAAA3G7izmy9cTBfkrToQL5MVVRXSNJVTQPraFTezWOxzb///W91795drVq1UqtWrXTNNddo3bp15v3jxo2T0Wi0+Kdfv34W5yguLtbDDz+stm3bqnnz5ho5cqSOHTtW17cCAAAAAEC1KsMKSUrNLtMvOfYbbiY19te1rYLqalhezWMVFs2bN9dTTz2lCy64QBUVFVq2bJluu+02bdq0SR06dJAk9e7dWwsXLjR/JyAgwOIcU6ZM0WeffaZFixYpMjJSjz76qEaMGKHNmzfL15c5PwAAAACA+uGG1kFKiQ/WgLgg+RhY0lTyYGAxaNAgi8+PP/64Fi1apD179gX4V+kAACAASURBVJgDi8DAQMXGxtr9fnZ2tt5++23NmzdPffr0kSQtXLhQSUlJ2rRpk/r27eveGwAAAAAAwAHlVXXXPMuNrRtpSJvgOhhN/eEVnTzKy8v1wQcfKD8/X8nJyebtO3bsULt27dSlSxfdf//9ysjIMO/79ttvVVpaqquvvtq8rWXLlrrooou0a9euOh0/AAAAAABVKSqvObBoRqNNGx5tuvnDDz+of//+KioqUkhIiN555x0lJiZKkvr166fBgwcrPj5eR44c0bRp05SSkqJNmzYpMDBQ6enp8vX1VVRUlMU5o6OjlZ6eXu11U1NT3XZP7lDfxouGjecR3oJnEd6E5xHegmcR3oJn0VJWqSQ1qvYY08kjSs2pk+F4jYSEhGr3ezSwSEhI0NatW5WTk6PVq1dr3Lhx+vTTT9W+fXsNHTrUfFxiYqI6deqkpKQkrVu3TikpKbW+bn2Rmppar8aLho3nEd6CZxHehOcR3oJnEd6CZ9HW0bwyaVdalftvahOsbokt6nBE9YNHa04CAgLUtm1bderUSVOnTlVSUpLmz59v99hmzZqpefPm+vXXXyVJMTExKi8vV2ZmpsVxGRkZiomJcfvYAQAAAABwRHVTQi6K8NPrvSLrcDT1h1dNkqmoqFBJSYndfZmZmTpx4oS5CWenTp3k7++vjRs3mo85duyYDh48qCuuuKJOxgsAAAAAQE0Ky6oOLK6PZ1WQqnhsSsiTTz6p/v37q0WLFsrLy9PKlSu1bds2vffee8rLy9Ozzz6rlJQUxcbG6siRI3r66acVHR2t66+/XpIUERGhUaNGaerUqYqOjjYva5qYmKjevXt76rYAAAAAALBQXWAR7OdVdQRexWOBRVpamsaOHav09HSFh4crMTFRK1euVN++fVVYWKgff/xRy5cvV3Z2tmJjY3XVVVdp8eLFCgsLM59jxowZ8vX11T/+8Q8VFRWpZ8+eevXVV+Xr6+up2wIAAAAAwEJ1U0KC/aiuqIrHAosFCxZUuS84OFgffvhhjecIDAzU888/r+eff96VQwMAAAAAwGUKqwksGvkSWFSF2hMAAAAAANyo+ikhBBZVIbAAAAAAAMCNCCzODYEFAAAAAABuVFRe9b7mjejBWBUCCwAAAAAA3KigrMLu9hA/gzo18a/j0dQfBBYAAAAAALhRVRUW3WID5O/DlJCqEFgAAAAAAOBGRVX0sOjRNLCOR1K/EFgAAAAAAOBGBeX2p4Rc1YzAojoEFgAAAAAAuFFRmf3tnaLoX1EdAgsAAAAAANyosNz+lBA/+ldUi8ACAAAAAAA3KqyihwWqR2ABAAAAAIAbVVVhgeoRWAAAAAAA4Eb2KiwW9Yr0wEjqFwILAAAAAADcyHpZ067R/kppHeyh0dQfBBYAAAAAALhJeYVJJwrLLba90M0ofxpu1ojAAgAAAAAAN3nv10IdzfsrsDBIig/z89yA6hECCwAAAAAA3KDCZNL0b3Istg1vG6zIQF7FHcGvBAAAAACAGxzKKbOorgjwkR65LNyDI6pfCCwAAAAAAHCD3BLLZpuXRPqrNdNBHEZgAQAAAACAGxSUWwYWjfxotOkMAgsAAAAAgFcymUw1H+TFCssILGqDwAIAAAAA4FUW/pin5m8fV8eVafo6o8TTwzlnBVaBRbAvgYUzCCwAAAAAAF4ju6RCj+/JVkGZSUfyyvXk3pyav+SlrCssgqmwcArdPgAAAAAAHmcymfTBb4Va9VuhSir+2r7lRLFMJpMMhvr3sp9fVmHxmcDCOQQWAAAAAACPSCso15YTxerUxF8f/FqoZ7/NtXvcx4eLdEPr4DoeXe09uCPb4jNTQpxDYAEAAAAAqHMni8r1t1XpOlVcoSBfqai86mPHbDylV3oYNeKCRvL3qR8v/emFtjdEhYVz6GEBAAAAAKhz/zlSpFPFZ6ZMVBdWVLpvW5bGb89y86hc59uTpTbbisvr96ondY3AAgAAAABQ504WVdR8kJV3fylQeUX9eOn/+qTt6iYZ53DP5zMCCwAAAABAncsvO7fgob689G85UWyzzXqZU1SPwAIAAAAAUOcKys4teDhR4MD8EQ/LL63QngzbCos7Lw7xwGjqLwILAAAAAECdyy89t2qD4/neH1jsTC9RqVUeMzg+SD2bBXpmQPUUq4QAAAAAANzu99wypRWUK72oQv/am6Ofs8vO6Tx/2ll9w9Nm7cvV03tzJEnv9m2snWmW1RW3tGuk+T2MMhhYJcQZBBYAAAAAALdac7hQf990yqbq4FzklnhXH4gDWaXmsEKSbv3ilM0x17QIJKw4B0wJAQAAAAC4jclk0rwf8lwSVkhSnpc1rlzxS0GNx/RszlSQc0GFBQAAAADALU4VleuWL05pV7ptA8rqPHZZuPwM0uUxARr0n5MW+/JclXy4SE35SWKkn5oE+dbNYBoYKiwAAAAAAG7xxsECp8MKSerXIlD/vDRMVzYN1DPJERb7zrVZp7tEBFT/Wv33i1gZ5FxRYQEAAAAAcItpX+fUfJAdQX5/9XuIDbYMBPK8ILD4/lSp3j9UoI5R/vott+rmoX2aB7KUaS0QWAAAAAAAvEqQ71+BRai/ZbPK/DLPTgn5s6Bc/T/NUGF59cFJr2aBWnlNlHxotnnOCCwAAAAAAC5XVIvmmMFnBRYhfpYVFrkerrCYsz+32rBizpVG9WoWqLhQX1YGqSV6WAAAAAAAXO5Qjv2pEr2a1bxixtlTQsKsKyw8HFis/q2o2v0hfgbFh/kRVrgAgQUAAAAAwOV+zi61u/1CY82F/hYVFlaBhadXCTlWUF7t/mA/ggpXIbAAAAAAALjcwSz7FRaNA30UUs1LvY9B8j/rTdV6FY7sEs9VWGQWVR9WSFJPBypI4BgCCwAAAACAy/2cbT+w8PcxyFjNUqBBvgaL6RTWx54uqVCFyTOhxd4M+1UjlZ69IkKh/rxmuwq/JAAAAADA5fZl2n+579ciUMbAqisszl4hRJICfA0KPasio8Ik5XioymJPRkm1+0de0KiORnJ+ILAAAAAAALjUtydL9Iudppv3JYaqY5S/jIHVVVjYbrM+PqvEM30sfjxddYVF40Cfau8LzmNZUwAAAACAS31/yvLFPjk6QOuvjzZ/jqrmxd5e08rGgT76I/+v/hGniyvUOswFA3VSdjVBSVQQYYWr8YsCAAAAAFwq12rp0U5N/C0+T7i06rQh0k6YYb3tVLFnKiys7+tsBR5ebrUhIrAAAAAAALhUrtXSo+FWjTM7NQnQfYmhCvCRAnyks4sqbm0XYnM+68DitKcCi2oqLAbEBdXhSM4PTAkBAAAAALhUrlVTzHB/22ke05IjNC05QpJUWGbSuqNFatrIR91ibZcFjbRq0umxwKKaKoq7LrENWlA7BBYAAAAAAJeyrrAIq2Gpz2A/g4a0Ca5yv9dUWFjdl7+PFOJn0Dt9o3Sx0b+Kb+FcEVgAAAAAAFzKuhIhLKDqZUwd4Q09LErKTSr6q++nfA1S+ujmMhhqd2+oGj0sAAAAAAAuZd3rIbyGCouaeEOFhW3ViIGwws0ILAAAAAAALuXyCgurpp1ZxRU6mFWqKz5MU+ySY3ru25xand8R2VZ9OUJrGcKgZh77hf/973+re/fuatWqlVq1aqVrrrlG69atM+83mUyaMWOGLr74YjVt2lSDBg3STz/9ZHGOrKwsjR07VnFxcYqLi9PYsWOVlZVV17cCAAAAADhLdolzPSxqYlthYdJL+3J1MLtMxeXS9G9ydTSvrFbXqMnxgnKLz00bEVi4m8d+4ebNm+upp57S5s2btXHjRvXs2VO33Xab9u/fL0maPXu25s2bp5kzZ+rLL79UdHS0brzxRuXm5prPcdddd2nfvn1auXKlVq5cqX379un//u//PHVLAAAAAADZ9piwDhyc1TjItofF8kOFFttWWH12tWP5loFFixBft14PHgwsBg0apGuuuUZt27ZVu3bt9Pjjjys0NFR79uyRyWTSggUL9M9//lM33HCD2rdvrwULFigvL08rV66UJB08eFAbNmzQyy+/rOTkZCUnJ+ull17SunXrlJqa6qnbAgAAAIDzUmGZSaO+zFSP/wYrrdAysGhcy8DCekqIvR4WFaaqlxx1hT/yCCzqmlfUsJSXl+uDDz5Qfn6+kpOTdfjwYaWlpenqq682HxMcHKzu3btr165dkqTdu3crNDRUV1xxhfmYbt26KSQkxHwMAAAAAKBufPRbgT45XKTiCst+Ff4+Z5YtrQ2j9ZSQEtvAoty9eYVNhUXLEBbddDeP/sI//PCD+vfvr6KiIoWEhOidd95RYmKiOXCIjo62OD46OlonTpyQJKWnpysqKsqiK6vBYFCTJk2Unp5e7XXrWwVGfRsvGjaeR3gLnkV4E55HeAueRXjSo7uCJdkGE6UVrnk2g32CVfi/MKTCTjhxMvOUUlPTan2dqvycHijpr6oK35x0paaecNv1zgcJCQnV7vdoYJGQkKCtW7cqJydHq1ev1rhx4/Tpp5/WyXXri9TU1Ho1XjRsPI/wFjyL8CY8j/AWPIvwtNPbjlW5zxXPZtQ3f+oPqyqHsxkjI5WQEFHr61Tl9A9pkv5q7Nm1XUslRAe47Xrw8JSQgIAAtW3bVp06ddLUqVOVlJSk+fPnKzY2VpKUkZFhcXxGRoZiYmIkSTExMcrMzJTprHlKJpNJJ0+eNB8DAAAAAKgbVc36uLp5oEvObz0txJq9qgtXoulm3fOKHhaVKioqVFJSovj4eMXGxmrjxo3mfUVFRdqxY4e5Z0VycrLy8vK0e/du8zG7d+9Wfn6+RV8LAAAAAID7+fvYTyxuT2jkkvOH1tAHw509LArKKpRV8tcF/AxSTLBXvU43SB6bEvLkk0+qf//+atGihXn1j23btum9996TwWDQuHHjNGvWLCUkJKhdu3Z64YUXFBISomHDhkmSLrroIvXr108PPPCAXn75ZUnSAw88oGuvvZZSOAAAAACoQxUmk0rtlDhsuD5aXV00bSKohsDCnRUWmUWWTT6jg33kY6hdI1HUzGOBRVpamsaOHav09HSFh4crMTFRK1euVN++fSVJ48ePV2FhoR5++GFlZWWpS5cu+vDDDxUWFmY+x+uvv66JEydq6NChkqQBAwboueee88j9AAAAAMD5KqOwQmVWgcEftzdTqL/rqhCCfGuqsHBfYmEdWNR2mVY4xmOBxYIFC6rdbzAYNGXKFE2ZMqXKY4xGo1577TVXDw0AAAAA4IQTBZb9HS4x+rk0rJCk4BoCi1LblU5dYldasUZ+kWmxrUkQ/SvqAgvHAgAAAABq5bhVYNGsketf6GuaElJgXeLhAlnFFbph3UkVWS1O0iSICou6wK8MAAAAAKiVo3lWgYUbVtCoqcKiyA1dN1ccKrAJKySpMYFFneBXBgAAAADUyoGsUovPCeGuL+YPquGUeW6YE5JWaCetkNSSJU3rRK0Ci+LiYpWUlLhqLAAAAACAeqa8wqRdaZbvhRdHuj6wqKnCIr3Q9YGFbxUrgVzZNNDl14Itp56iffv2adWqVdq2bZsOHDigvLw8SVJoaKguueQS9ejRQykpKerYsaNbBgsAAAAA8B7F5Sa1X/GnMostw4Kkxq5ZyvRsNU34yHBLYGG7LczfoE5R/i6/Fmw5FFisXbtWzz//vL755huZTCbFxcXpsssuU+PGjWUymXT69Gn9+uuvmjVrll566SV17txZEydO1LXXXuvu8QMAAAAAPGTJz/k2YUXvqDK1cMOUifzS6iOLjKJymUwmGaqoijgXpRW210xq7C8/H9ddA1WrMbAYPHiwtm/frh49emju3Lm65pprFBMTY/fY9PR0rVu3Tu+9955uueUWXXXVVVq9erXLBw0AAAAA8LzNx4tttj3YttTOkbWXX8MqICUVUnaJScZA14UJOSX2AwvUjRoDi4iICG3ZskUdOnSo8WQxMTEaNWqURo0apX379mnmzJkuGSQAAAAAwPscsVod5O6LQ9Q0sMAt1yp0YNnSzKIKGQOdb9VYXmFSRlGFGgf6KOCseSDZdhp53prQyOnz49zU+Cf5zjvvOBRWWLv00ku1dOnScxoUAAAAAMD7Hckrs/j8YMcwt12ra3TNfTHyy5zvY5FfWqHr157UxSv+VMyS45q7P9e8z7rCIiLAoI5Rru/PAftY1hQAAAAA4LTskgplnfVCH+grxQS77xXzNgcqG2qaNmLPhmPF2nHWKieP78nRrrQzU10KrM73Zu/GTp8f587ptWYKCwu1c+dO/fLLL8rNzVVYWJgSEhLUrVs3BQUFuWOMAAAAAAAvYz0dpFWIn3xc2PDSWniAj9qE+eq33PIqjxnw2UmtH9REyTGOLzu64Ic8m22v/JCnK2IDVWhVsdHIj2abdcmpwGLOnDmaNWuWcnJyJMmiA2t4eLgeeugh3Xfffa4fJQAAAADAqxzOtZwOEhfq+pVBrMWF+lUbWEjSY7tztP76aIfP2TjItipkb8aZigvrCotgAos65XBg8cQTT2ju3LkKCwvTyJEjlZiYqLCwMOXm5mr//v1as2aNnnjiCWVmZmrq1KnuHDMAAAAAwMPmfG9ZmVAXgYWfAzNOdmeU1HzQWewtwWoM8FGFyaQfTluGMlRY1C2HAosffvhBr7zyinr16qU333xTRqPR5pisrCyNHj1ac+bM0fDhw9W+fXuXDxYAAAAA4Hkl5SbtP225fGnbcKc7DjjNz8f1gUGYv+05f8wqU9cP0my2BzuSmMBlHPq1ly5dqtDQ0CrDCkkyGo166623FBISonfffdelgwQAAAAAeI99p0ptpkvc2CbY7de1ky3YVV7hePPNkipmmPxqZ+oJFRZ1y6HAYs+ePRo8eHCVYUWlyMhIXX/99dq5c6dLBgcAAAAA8D47/7eKRqWBcUFqFer+Cgt/ByssCsudCCycCDeCfQks6pJDgcVvv/2mpKQkh0546aWX6vfff6/NmAAAAAAAXqiswqTp3+TosT05Ftt7NnN8VY7acHRGRqETy5uWOBFuBLq/TQfO4lAElpOTU2N1RSWj0ajc3NxaDQoAAAAA4H2e+Cpb83/It9neLSagTq7vaA8L5yosHL++wY3LtsKWQ/lUaWmpfH0di5J8fHxUWlpa84EAAAAAgHojq7hCr/9kG1ZIUofG/nUyBn8HKyyKnKmwcGJKCOqWw5OMjhw5om+//bbG4w4fPlyrAQEAAAAAvM9XGSV2qxF6NQt0y+od9jjaw+Lrk6W60OhYiFLsRDUG6pbDgcUzzzyjZ555psbjTCYTZTIAAAAA0MDsziixu31cYkidjcHRnpf3bD2twfFBCnGgJMOZKSGoWw4FFpMmTXL3OAAAAAAAXmx3umVg0atZoJ7qGq5OTeqmf4XkeIWFJL2dWqB72ofWeJyjTTendA5z+NpwDYcCi8mTJ7t7HAAAAAAAL1VeYdJeqwqLF/8WoXYRddO7opKjPSwk6Vh+uUPHOdLD4vVekRraJtjxi8Ml3L9QLgAAAACgXvspq0y5pX+92DcO9NEF4XX/OulMr4wyB5tp1lRhERvso2FtGzl8XbhOrZ+w3bt3a+nSpTpx4oQuvvhi3XvvvWratKkrxgYAAAAA8AJfn7Ssrrg8JsAjvQv9nLhkmYO9KWrqYVHoxIojcC2HCmpmz56t1q1bKyMjw2L7+++/r4EDB2rJkiX6/PPPNXfuXPXt29fmOAAAAABA/XU0z3J6RVJk3U4FqeRMD4syk2sqLEZdWHdNRWHJocBi69at6ty5s6Kjo83bysrK9Oijj8rX11ezZ8/W9u3bNWXKFJ04cUJz585124ABAAAAAHUrrdAysGjayIlmEi7kTA+LUocrLKoPLP5fYs2NO+EeDv1xHzhwQF26dLHYtn37dmVkZGjMmDEaPXq02rdvr4kTJ2rAgAHasGGDWwYLAAAAAKh7aQWWgUVMsK9HxnGR0bKyo3k1wUmpAz0sispMNTbnbOahcAYOBhaZmZmKi4uz2LZr1y4ZDAYNGjTIYnuPHj105MgR140QAAAAAOAR+zJLtOhAnnZZLWnqqQqLvi0CdfclITJICvY16PEuEVUe68hqpTvTi1VUw2IinujVgTMcarrZqFEj5efnW2zbu3evDAaDTeVFeHi4ysrKXDdCAAAAAECd25NeooH/ybA7tSLWQxUWfj4GPd/NqGcuj1BxhUlh/j4at/W03WMdqbDYeKzY1UOECzkUi8XHx2vTpk3mz0VFRdq5c6fat2+v0FDL+Tzp6elq0qSJSwcJAAAAAKhbH/1eYDesaB3mq7hQzwQWlQJ8DQqroaGFI6uEbDxuGVg0DmT6hzdx6E9jxIgR+vzzz/XYY49p/fr1uu+++5Sbm6sbb7zR5tidO3eqbdu2Lh8oAAAAAKDuzP8h3+72lPjgejFNoqyGCovMonLtO1Vqsa1ns0B3DglOcmhKyN///nd9+OGHmjdvnubPny+TyaSOHTvqnnvusTguLS1NGzdu1OTJk90yWAAAAACAexSXmzTt6xztSivR4NZBam/0049ZttP9LzY69BrpcTWtErLZqrri0sb+igqiwsKbOPSkBQYG6rPPPtOaNWv066+/qk2bNho4cKD8/S07tKanp+vxxx/XkCFD3DJYAAAAAIBr5JZW6OmvcvTVyRKNvKCR/HykufvzJEm7M0qq/N6FVit1eKuyGlpYbDlhGVj0aR6oC41+WnTWtmBf768kacgcjsZ8fX2VkpJS7TFJSUlKSkqq9aAAAAAAAO5TYTLprs2nte5okSTpm5PZDn+3Q2T9CCxqarr5babldJAezQLVs1mgZnyTqz/+t9Tpqz0j3TY+1Kx+1PIAAAAAAFzmlf155rDCGcnRAQryqx9VB+XVTAkpqzDppyzLwKJjlL8CfQ3akhKtT48UKSHCT3+LpaeFJzkUWAwePLjKfQaDQcHBwYqLi9P111+vXr16uWxwAAAAAADXKq8w6Ymvcs7pu1M6h7l4NLV398Uh+vcB2wahpaaqKyxOFJSruPyvz1GBPor531KtjYN8NfrCEJePE85zKLDYtm2bQydbtGiRhg8froULF9ZqUAAAAAAA95iwI+ucvvfzyKbml3pv8sClYfYDi2oqLHJLLcOMJjTb9EoOBRanT5+udn9BQYF+/vlnzZ8/X++//766d++uMWPGuGSAAAAAAADXeevnAqe/0zbM1yvDCklqHuKrSZ3CNPPbXIvt5dX0sMgtsUwzwgLqxzSX841LYqRGjRqpU6dOWrhwoS6//HItXbrUFacFAAAAALhQTkkNa31WIbaRd4YVlcIDbF9tq6uw+PC3QovPof5UWHgjl/6pGAwGDRgwQAcOHHDlaQEAAAAALjBm46lz+l5MsHe/0NtbfbSsih4WJpNJC3+ynEISWk8aiZ5vXP7URUREqKjI+W6zAAAAAAD3OZxbpo3Hi2s87qmu4TbbYoK8u8LCXt5QVkWFRVG57bay6ldAhYe4PLA4ePCgYmJiXH1aAAAAAEAtvPBdrs22NmG+Mp7VvyEq0EeD4oJsjmsR4t2Bha/BNrEoraKHRZ6duSLZ5zhVBu7lUNNNR/344496++23NWTIEFeeFgAAAABQC7/llOndXyybbQ6MC9I7VzfWL9lleun7PKUVlOuBS8MUF2r7mnhBhEtfHV3Ox06FRVU9LPJKbYMMAgvv5NBTN3PmzGr3FxYW6uDBg9q4caMCAgL04IMPumRwAAAAAIDaW36oQOVnvadfEO6rJX0ay8dg0IVGfy24KrLa78eFeneFhZ0CC5X874Z/PF2qB3dkKb/UpH9dHq7IQNuJBq3shDTwPIf+VJ599lmHTpacnKznnntObdu2rdWgAAAAAACukVNSYbPk572JofKzV5bwP9e1CtLao2d6E7YJ81WHSH+3jtEdiv4XWEzcmaUdaSWSpHFbT+u1Xo1tjn0gKbROxwbHOBRYfPLJJ9XuDw4OVnx8vJo0aeKSQQEAAAAAaq/CZNKIDZk22ztFBVT7vdndjXr66xzllVbo4Y7h8q0m3PBWZSapvMKkbX+WmLcdL6jQvsxSm2OviKn+94BnOBRY9OjRw93jAAAAAAC42FsHC8zVBWdLqKEnRWwjX83rUf00kfqg2E7jzRyrfhUp8UEy2JtTAo/z7sV0AQAAAADnpKjMpCf3Zttsv7ZloMIDGtarYFVxQ7GdJUy/PmkZ4IT6N6zfoiGp8U9myZIlqqhwvmNqeXm5lixZck6DAgAAAADUzneZJcousawwuC2hkRb1tu3h0FDZW8J0/R/FFp9D/amu8FY1BhaPPfaYLr/8cr322mvKzLSd+2QtPT1d8+bNU9euXfX444+7ZJAAAAAAAOdYhxVXNw/UvB6R51VFQa6dJUythRFYeK0ae1h8/fXX+te//qVHHnlEjz32mDp37qzLLrtMbdq0UWRkpEwmk06fPq1Dhw7pq6++0vfffy9JGjVqlB555BG33wAAAAAAwFZ+mWV1QUOuJKiqBcXWE8X2d5zlfApw6psaA4smTZpo9uzZmjRpkt544w19/PHHevXVV+0ee8kll+ihhx7SmDFj1LRpU5cPFgAAAADgGOvqgvPxxXzSLtseHtZC/BpukFPfObRKiCQ1b95cjz32mB577DFlZGTowIEDyszMlMFgUFRUlC655BJFRUU5fOFZs2bpk08+0S+//KKAgAB17dpVU6dOVfv27c3HjBs3TsuWLbP4XteuXbVhwwbz5+LiYj322GP64IMPVFRUpJ49e+rFF19UixYtHB4LAAAAADQ0eTaBBS/m9vC7eC+HA4uzRUdHKzo6ulYX3rZtm+68805ddtllMplMmj59uoYMGaJdu3YpMvKv5XN69+6thQsXmj8HBFiujztlyhR99tlnWrRokSIjI/Xoo49qxIgR2rx5s3x9fWs1RgAAAACor6wbTjbkXg21ubPzsfKkvjinwKJScXGxMjMz1aRJX3EiWgAAIABJREFUE5sgoSYffvihxeeFCxcqLi5OO3fu1IABA8zbAwMDFRsba/cc2dnZevvttzVv3jz16dPHfJ6kpCRt2rRJffv2dfKOAAAAAKBhsK6wCOHF3K6GHOTUd+f0xH777bcaPHiwWrZsqQ4dOmjHjh2SpIyMDKWkpGjTpk1OnzMvL08VFRUyGo0W23fs2KF27dqpS5cuuv/++5WRkWExjtLSUl199dXmbS1bttRFF12kXbt2ncutAQAAAEC9t+l4kebsz7PYFkqvBruosPBeTldY7Nu3TwMHDlTjxo01cuRILV261LwvOjpaRUVFevfdd9W7d2+nzjt58mQlJSUpOTnZvK1fv34aPHiw4uPjdeTIEU2bNs0ciAQGBio9PV2+vr42vTOio6OVnp5e5bVSU1OdGpun1bfxomHjeYS34FmEN+F5hLfgWYQk5ZdJt+8JlvVEifxT6UpNPVEnY6jrZzEtzVdS4Dl9N/P4EaVm17z8KVwvISGh2v1OBxbTp09X06ZNtWXLFhUXF+udd96x2N+zZ0+tWrXKqXM+8sgj2rlzp9auXWvRd2Lo0KHmf09MTFSnTp2UlJSkdevWKSUlxdmhm9X0o3iT1NTUejVeNGw8j/AWPIvwJjyP8BY8i6i08Mc85ZXbro5xQctmSmgd7Pbre+JZbKp8KTXrnL6b2K61WoXWqlsC3MTp2pcdO3ZozJgxCg39/+zdeXhU5dkG8PvMviWZ7AsJe8ImgqJsIrIoiAoWRUUr1q22at2+T6tov1q1FS3W2sWt2tJaW8EFFdwQFARRQDZB9j0QsiczmUlmn/P9ETLJmTkzmck6k9y/6/K6zDlnJm/IJJn3Oc9igiAz7LagoABlZWVRP9/ChQvx3nvvYcWKFejfv3/Ea3Nzc5GXl4ejR48CALKysuDz+VBdXS25rrKyEllZWVGvgYiIiIiIqCfwiyJe21cve86s7bmlD5f300PTxi8viSUhcSvm74zL5UJycnLY83V1dVE/18MPPxwIVhQVFbV6fXV1NUpLSwNNOEePHg21Wo21a9cGrikpKcGBAwcwbty4qNdBRERERETUE2wqd+NwnVf2XIqm5/awSNEo8NwEc+sXyjCy6WbcijnvZcCAAdi5c2fY8xs2bMCQIUNafZ4HH3wQy5Ytw5tvvgmz2Yzy8nIAgNFohMlkgt1uxzPPPIM5c+YgOzsbxcXFePLJJ5GZmYkrrrgCAJCSkoIFCxbg8ccfR2ZmZmCs6YgRI2LuoUFERERERJTo9tR6wp5LaWsKQoK4qciINw7WY2tl+H+DYFoloFYwYBGvYg5YzJs3D4sXL8bcuXNx9tlnA0CgNOQvf/kL1qxZg2eeeabV53n99dcBAFdeeaXk+MMPP4yFCxdCqVRi7969WLp0KaxWK7Kzs3HhhRdiyZIlSEpKCly/aNEiKJVK3HLLLXA6nZg8eTJeeeUVSS8MIiIiIiKi3uCU3Rf2nLmHByyo54k5YHHPPfdg7dq1uOqqq1BUVARBEPDoo4+iuroa5eXlmDp1Km6//fZWn8diidwQRa/XY/ny5a0+j1arxeLFi7F48eKovwYiIiIiIqKe6KBVvhwEAJJ7cElIEzHGYR+u8PEdigMxh9g0Gg0++OADPPXUU9DpdNDpdDhy5AjS0tLwxBNPYNmyZVAoGLkjIiIiIiLqSk6viNWnnGHPK2SGJvQ0HE7as7RpdotKpcLdd9+Nu+++u6PXQ0RERERERG3wbbkL3jA79iEpvWNsJwMWPQtTIYiIiIiIiHqAk/Xh6xt+cZapC1fSfc5KVXf3EqgDxRywePrppzFhwoSw5ydOnMh+EkRERERERF3s3o3SPoE/HWbEBzPTsf3qbCwoMnbTqrrWQ6OToIyh8iWZI03jWswBi48++ijiyNCpU6fiww8/bM+aiIiIiIiIKAbHbaHNNotSVJiSp8PA5N5RDgIAfU0qfH55ZtTXPzMupRNXQ+0Vc8CiuLgYRUVFYc8XFhaiuLi4XYsiIiIiIiKi6K077Qo5VmBSdsNKut+YTA3StfJb3QtzNIH/v26QHtcPNnTVsqgN2hRqs1qtYc9ZLBb4fJwNQ0RERERE1FXWl4YGLKbk6rphJfFBEyZW8/YlGThc50WmToEcQ+8M6CSSmDMshg4dik8++UT2nCiK+PTTT1FYWNjuhREREREREVHrRFEMCVi8fXE6dKre259BrZD/2jUKYGSamsGKBBFzwGLBggX47rvvcOedd6KqqipwvKqqCnfffTe+++47LFiwoEMXSURERERERM28fhF/3m3DT9ZW46a1Nahy+gPnktQCpvXRduPqup86zE43TByD4lTMJSE/+clPsHHjRixduhTLli1DTk4OAKCsrAyiKOKqq67Cbbfd1uELJSIiIiIiokZvHW7Ar7fWyZ6bmK2BqpfvzDUyX79KAAShd/+7JJo29bD429/+hlmzZuHtt9/GsWPHAADnnHMOrr32Wlx55ZUdukAiIiIiIiKS2lAW2rOiyeS83tu7oolcSYgq5voC6m5tnm8zd+5czJ07tyPXQkRERERERFGwusWw567sx4CFXNNNFbMrEg5jTERERERERAmmzu2XPT4hW4N8U5vvS/cYchkWSu5+E06rr+S33noLADB//nwIghD4uDXXX399+1ZGRERERBQHDlk9+KLEhQnZGoxK13T3cogAADaPfIbFfSNNXbyS+CTfw4IZFomm1YDFXXfdBUEQcPXVV0Oj0QQ+FsXwKUiCIDBgQUREREQJ77jNi0kfVsDla2zYt/qKTJyTwaAFdb/gDIvrBxtw7UA9pvZhOQggPyWEPSwST6sBi5UrVwIANBqN5GMiIiIiop7uue9tcPka/98rAs/vsuHf09K7d1FECA1YPHV+MjJ0Mo0beinZppvMsEg4rQYsJk2aFPFjIiIiIqKeaunhBsnHK084u2klRM1EUQwpCUmWSynoxeSabrKHReKJ6Vtmt9sxevRovPTSS521HiIiIiKiuOENXwVN1G3qvSJ8LV6bOiWgUTJ7oCX5HhbdsBBql5jax5pMJtTU1MBkYiMXIiIiIkosFpcfr+6z49tyNy7I1uB/RyVBwRRxSkDlDdJykHQtS0GCyZaEyByj+BZzUsz555+PHTt2dMZaiIiIiIg6xbtHGzDq3TIs2mHDutMu/G6HDcuOOCI+xiGTXqHnXWzqZn5RxDflLsmxvkkMWARL04ZudZlhkXhiDlg8/vjjeP/99/Hmm29GnBRCRERERBQPKh0+/Hx9Laxu6XvXD447YPP48dVpF8obfCGP21frCTnm8IkYu7wcbx9pCDlH1Nn21Hhw9jvluGejRXK8wMSARbBzMtQhx5TMsEg4MZWEAMBjjz0Gs9mMe++9F48//jgGDBgAvV4vuUYQBKxYsaLDFklERERE1FbbqzyyvSjWnHLiwg8rcNzmQ7JawKrLMzEstXGT4xdFPLGtTvb5Dlq9uGtDLS7uo0UapzJQF/rDLhtO1YcG1/qaYt7W9XjnZXL8cE8Q8yv7+PHjEAQB+fn5AICKiooOXxQRERERUUc5ZvPKHveJwHFb4+avziPiqe11+O/0xpGl/zrQgK9KXbKPAxqbca465cL1gw0dv2CiMI6HeS33ZYZFCLl/k0PW0Kwpim8xBSyqqqqwZMkSpKenY8CAAZ21JiIiIiKiDnOsTn6TF+yT4saRpX5RxB9321q9nvXw1JU+OObA9ir5DTcDFqEEQYBZI8DSohTMGZqcQnEuqh4Wfr8fDzzwAIYMGYIZM2ZgzJgxuPTSS1FVVdXZ6yMiIiIiapcjUQYsmhy3+VBsb31no2fEgjrIcZsXP1tfg198XSvbT+Ww1YPbv6oJ+/gCI0tC5IzOYFlIoovqlf23v/0N//znP5Gbm4vzzz8fR44cwebNm3H//ffjzTff7Ow1EhERERG12b7a6AMWbp+ISkd0t2FdvuY7tyuOO/BliRMzCnS4rK8+wqOIQv1kbQ2+r27Mnvi42IG5/Q1w+0XcP9KEwSlqvLK3XrYPCwCYVALymWEh687hJqw73VzadfUA/mwmmqgCFkuXLsWQIUOwevVqJCUlAQDuvfde/Pe//4XFYoHZbO7URRIRERERtYXV7UeJzB3rcA5ZvXj3mHTcaV+TEha3H3VBU0Zu+6oWv9teh6Gp6kA5yT8PNmDlpRlYcqAeq085Ma2PFi9NSoVRHfNwPuol6tz+QLACAGpdIv5xoB4AsKncjc1zs7DPIl8KIgBYeG4ytBy3K2tGvhazCnT49KQTyWoBPx1m7O4lUYyi+s15+PBh3HDDDYFgBQDccccd8Pl8OHLkSKctjoiIiIioPU5GUdrR0s5qN17bVy85NjFbgw1zsmSvP2rzBYIVTWZ/VoXlxxyweUR8eNyJD487ZB9LBAA2T5jUCQCH67x4cY8dG8vcsucPzs/B3SNMnbW0hCcIAv47PQ3fXZWFXdfkYHy2truXRDGKKmBRX1+PnJwcybHc3NzAOSIiIiKieHQ6aARkazeiH9tiDTnm8QP9klT4+fC23Z39TZjxqEQAYPf4I57/9dbwr59MPUtBWiMIAgpT1DBrmeWUiKL+rgmCIPuxKIaPCBIRERERdafSoHKQmQU6KCIELSzu0Pe2Na7GDaW+jWn3fLtMkdgjZFgQ9XZRt5NdvXo1ysvLAx87HA4IgoAPP/wQu3fvllwrCALuvvvujlslEREREVEbBPevGGpWweHVYm2LRnyt+XGhAQDa3CcgQ8c7uxReaxkW4Rg5pYZ6gagDFu+88w7eeeedkONLliwJOcaABRERERF1B1EUYXWLgfTv/bXSZoX5RhUGJ6uiDlj0NSkxq0AHoO1jTNMZsKAIIvWwiGRAMkeZUs8X1at85cqVnb0OIiIiIqJ2afD6Me/zanxT7sZ5mWq8fXE6tlVKAxaj0tUoTFHhrq8trT5fjl6B767KDmRW6NqYYZHK2nmKoK0lIU+dl9zBKyGKP1EFLCZNmtTZ6yAiIiIiapflxxz4prxxmsLWSg+KlpbB22IvqFYAI1LV0KkE3FhowJuHGiI+3/+cnSQpA2lrwIIjJymStpSEzB+kx5Q8Trygno95RERERETUI2ypkI5+9AbduJ7bXw/dmbKOReNS4PKJOFznxZgMDf5xoB7+FtfnGhS4brBB8nhdG0tCPH42VaTwgktCpuVp4faL+DpolOk1A/V47aI0uH0iNAyCUS/BgAURERER9QgNwRGKFgwqAY+flxL4OEmtwGsXpQU+XlBkwPrTLhyweiEAuH2YESkaaSlHW5scun2tX0O9V0nQ6N2L8rRYUGjAX/fYsavaA51SwJhMDe4Y1jhWl8EK6k0YsCAiIiKiHsHqCp9a/79nJ6GPURn2/Kh0DUalayI+f2FK2946M8OCItkT1Bh2YLIKaTolfj0mJcwjiHoPdgAiIiIioh6hKkzAosCkxJ0jjO1+/kEyUxkuzNHgwpzIgQ6XjwGLnmpnlRurTjrbFJTy+kUs3GzBt+XS0o+BSbynTNSEAQsiIiIi6hGqnKEBi0HJSiydng6Dqv1ve1UKAVf01QU+ztYr8MHMDKyclYn/Tk8L+7g29FSkBPDvg/WYsrIS162pxjWrq8Ne98IuGy78sAJ3bahFlbO5/OOPu2x4eW+95FqNAhiQHD4TiKi3YfiOiIiIiBKeKIqocEh7Aey/LgfZegUEoeNq/n8/3gyj2gqLW8Qjo5OgVDQ+92V99fhqTiYuWlEZ8hg3S0LaxOsX8cpeO7ZWenDdID1m9dV395Ik7vumeTTuutMu/FDjwVlpask1X5e58JttdQCA3TUenLB78fGsTADA2tOukOe8/+ykDgmuEfUUDFgQERERUcKrcvrhahGvSFYLyDF0/J3qPKMSr06Wz6YYmaZGqlZArUsaoHAzw6JN/n2wAb/6rnGz/0mxA2tnZ2FEUECgOwXHofbWhgYs1pVIgxIby9yBKR8VDukL46YiAx49J7lT1kqUqBi+IyIiIqKEdypo0kKkBpudRSEIuHVIaK+MH2o8eONgPWysDYlaeYMPD3zbnMHg9gNPbrN244qk/GJ0WTPP7bKFHHOc6WlS4ZS+Zn89hsEKomAMWBARERFRQqpz+7HqpBOHrR58fsopOdcdAQsA+OXoZNw/0hRy/N6NFsz6pAo+lodE5Z2jDSHHVp1yQYwyUNCZvH4RmyvcIcftnua1ldT78OFxh+zjD1q82FzuQp27+XqlAKRpuTUjCsaSECIiIiJKOHtqPLj68yqUOeSzFoaau6d0QKsUcNtQI17YbQ8590ONB5+cdGJ2v/jqxRCP3jgYGrAAgJ3VHpyTEXkqS2fxiyJ+vqEW7xxxQC5sUn0mY+KlPXY8tsUqew0AXPJxaJ+TLL0Cig7stULUUzCMR0REREQJ5YjViytXhQ9WaBTArUPbP8a0rTSK8BvPlSfk77pTY0BgY5kLu2s8SNfJb1O689/v42In3g4TrACAapcfflHEoxGCFeFk6TkZhEgOMyyIiIiIKKH8YmOt7AjTJlcN0GNgcve9zdUowwcsSoJ6bVCzn2+oxdtHIgckvq/2dNFqQn0lM9WjpRqnHw3etpWsZOt5H5lIDn8yiIiIiChhHLd58W15aP+AJulaBR4/L6ULVxRKE+EdtsvX/T0Y4lGlw9dqsAIArN04ckWub0VL1S4/HG0MWDDDgkgeAxZERERElDBay1B4c3oacjthnGksDCohbAPFlo0Wqdkxmzeq66xd/O/n8Yt4da8d5iUl2F0TObuj2ulHfRsDFimRolxEvRh/MoiIiIgoYdRFuMO+dnYmJmRru3A18gRBwIhU+ZKUSidLQuQcrYvu36UzMywqHD68cbAeH59wBDIl7v66Fg9vlh+nGhxjaE+GRa6B2zIiOexhQUREREQJI/gO+5x+OiyZkgZlhEaX3eGsNDU2lIWWENS6RHj8ItRxtt7u9PlJJ36+oTaqazsrYGF1+3HBBxWoPNMbJd+oxONjksOWqUzI1uA/09Iw8K2ywLFqpx/7LW3rsXFhbvcH2ojiEUN5RERERJQwgjMsMvXKuAtWAMCItPBjVSvDTDfpjXZUufHjL6ujvt7lA5xtzGKIZMVxRyBYAQCn6n346frwQZTrBxuQqlVA1eKl1+AVccu66AIvTc5KU+PpsSkYld49o1qJ4h0zLIiIiIgoYdR5pJvVZHX8BSsA4KzU8AGLsgYf8oxssggAL++xwxNj/ObdYw24sbBjx9Zuq4zcUDPYuCwNBEFApl6B0obYA1AGlYAtc7OQb+J2jCiSbsuweP755zF16lQUFBRg0KBBuO6667B3717JNaIoYtGiRRg6dChycnJw+eWXY9++fZJrLBYL7rjjDvTt2xd9+/bFHXfcAYvF0pVfChERERF1keCSgOQ4bVY4xBw+YFHawD4WTXYFNbKcmK3B2RGyUwDgs2Jnh68j0uQZOYUpjYGG7DZO93htciqDFURR6Lbf8F9//TVuu+02rFq1CitWrIBKpcKPfvQj1NY2p1H96U9/wosvvohnn30WX375JTIzMzF37lzYbLbANbfffjt27dqFd999F++++y527dqFn/3sZ93xJRERERFRJwsuCYnX6Qp6VfjMj94esKhz+/HCLhue2mbFfot0Osg/pqRhyZS0iI8/1cqkmFgdt3lxwBrdlBIAmD9ID4XQ+P3NbsNEmg9npuPyfvqYH0fUG3VbWG/58uWSj1999VX07dsXmzZtwqxZsyCKIl5++WXcf//9uPLKKwEAL7/8MgoLC/Huu+/illtuwYEDB7BmzRp89tlnGDt2LADgj3/8I2bNmoVDhw6hsLCwy78uIiIiIuo8wWMjTXFaEgIAPy404D+HGkKOl7WhhKCnOGz14LzlFbLnBAAZOgUMqsg9Kg5avfCLYiBo0BYVDh9SNApsKnfjmtVVrV7/10lmLD3cgDyDEk+clxI4nqtvPWA2q0CHSblafHXaiSv66XFRnq7N6ybqbeImD8lut8Pv98NsNgMATpw4gfLyckybNi1wjV6vx8SJE7F582bccsst2LJlC0wmE8aNGxe4Zvz48TAajdi8eTMDFkREREQ9THDDRZ0yfgMW/zMyCZvL3ThcJ717X+rovRkWP1lbE/Zcuk4BlUJAkkxFiFElBIJVDV4R1U4/MttYjvGbrVb8abcd0bbu/NW5ybix0CjbNyOaDIsnz09GYYoad48wxbhSIoqbgMUjjzyCkSNHBjIlysvLAQCZmZmS6zIzM1FaWgoAqKioQHp6OoQW0VVBEJCRkYGKCvnILQAcOnSoo5ffqRJtvdSz8fVI8YKvRYonfD12nRqbFkDzJrGm/DQOxdq1sQu9ORJYV63EI/ubx1YeqbTh0KHW7+q3RTy/FstdAvbUhi+FSFF4A+t/YIAKLxxTQ4SAO/u58WmFCvXe5myG7w4cQ6Ex9mkhn1Qo8cLB6EeIDjD4caWhDIcOlcmeV9hUAOQnfCgh4l+jnUDFcRwKvzXpseL5tUjxo7Ukg7gIWDz66KPYtGkTPvvsMyiVnd8xOZEyL1jaQvGEr0eKF3wtUjzh67FrKQ9XAmhukDigIB+FedFvQLuDs8oN7K8MfFwHLQoL+3b454n31+Lne+wArGHPj8wyorCwAADweCFw07le+EVgUIoKuz+txHFH8/ddl5mPwj6xlVb4RRGPf3261euen2DGb7ZaYVILeHlKBgqzw7++ztY6gCOhWSMX99HiyfNTMDzCtJieLN5fi5Q4uj1gsXDhQixfvhwrV65E//79A8ezs7MBAJWVlSgoKAgcr6ysRFZWFgAgKysL1dXVEEUxkGUhiiKqqqoC1xARERFRz+EKqqbQJcB00NygsoHeWhKy/GhoP48m/UxK/HJ0kuTYgOTmrUrwNI5yR+xZNRVRPGZmvha3DjXix4UGqBVotU9GTpiSkMXjzZL1E1HbdGtb5YcffhjvvfceVqxYgaKiIsm5fv36ITs7G2vXrg0cczqd+PbbbwM9K8aOHQu73Y4tW7YErtmyZQvq6+slfS2IiIiIqGdw+qRlANo47mHRJEOnQMtl1rrEkF4cPd0puxfbqqQjTH861Iinx6Zg09ws7JyXHTEbIdsg3bZUtCHoU+1sPWDx8OhkAI2vq2iaesoFLAwqAf2SEiCSRpQAui3s9+CDD2LZsmV48803YTabAz0rjEYjTCYTBEHAnXfeieeffx6FhYUYPHgwnnvuORiNRsybNw8AMGTIEFx88cV44IEH8MILLwAAHnjgAcycOZMpSEREREQ9SEm9D5UOH+xB/Sp0EcaHxgulQkCOXomSFuNMyxw+9E/qeXfgXT4RL++xo8blx8+Hm5BnbNy4/+ugNLtiXJYGiyeYo37e0AyL6AMWoihiV40nZIRqsAdHJeHcTPl+FOFk6kLv/+Yble2aYEJEzbrtt+Trr78OAIGRpU0efvhhLFy4EABw3333weFw4KGHHoLFYsGYMWOwfPlyJCUlSZ7nl7/8Ja6++moAwKxZs/D73/++i74KIiIiImrJ5vGjyuFHv6SO27StOeXEDV9Uwy1zgzyep4S0lGNQSAIWpQ09M2Dx2BYrXt9fDwD49KQTW+Zmwe0H/nHmWJNpfWLrO5IVFLCIpryjye1f1eK9Y45Wr7u5yBDTmgBApQh9/ckcIqI26rbfkhaLpdVrBEHAwoULAwEMOWazGX/72986cmlERERE1Aa7azy4alUVKp1+zMjX4l9T06HvgAyI53fZZIMVQGKUhABNpQPNJRE3flGDjy/LwFBzz2rK+HqLwMQha2MZiMMrotol/QZeNyi24EC2XprJUN4QXYbFAYsnqmDFULMKfYwdU8Yh9q5qH6JO1a09LIiIiIioZxBFEXdvqEXlmT4Bn59y4YXdNnj87du9+fwivil3hz2fKBkWeUG9Dqpdflz2SRUavPE7krUjlDb4sKncJTk2u58u5uyStmZY/FDjCXtuQaEBPx1mxI2FBiy9OD3QxJ+I4gcDFkRERETUbgesXuwK2hw+u9OG4cvK8NGJ1u9wy9lW6cZNa0NHRrakTZDehoUpoRv0Gpcfq0+5ZK5OTKJMaoHTK+KYTZoNMTk39jG0wRkWZVH2sDhoDd+34sr+eiweb8ZfJ6W2qzxnZJo0S2ZqjOUuRBQeAxZERERE1G6rTzplj1c6/bh5bQ18UWZarDjuwNSVFTAvKcH0jyrxcbH88zbRJkjDgBFp8qUfJ2yRG0EmkuCRswBgdftRbJd+jf1MsQcH0rTSSStWt4j9lvDZE0BjAOXTMK+fSwt0MffRCOep85MD/69RAL8YYeqQ5yUiBiyIiIiIKIIqpw/7LR7Zu+dNKh0+vLDbHva8VwSe2WmL+Hn21npgXlKCm9bWYEdV5I1oE7WicQJHIhiULL9Jr4pi1GaisMuUtxyweLG3Vhqw6NuGkZ9KhRAykWP8+xX4oiR8QOubcndI1g8ATM3TYsmUtA5rCjslT4cVl2bgV+cmY92cLOS3ISBDRPIYsCAiIiIiWetLXRj9TjnGv1+Bm9bWhA1aPLW9LqSpYrC//hA+oOEXRdy6LnLph5xE6V8BAGaN/Nvuo3U9J8PC7gl9fby2vx41LV4beqXQpgwLILSPBQDct9ECf5jX5St7pa+5ohQVVl2WgfdmdEwz2JYm52rx4KgkDE/tWU1UibobAxZEREREJOvPu22wexs3gytPOPFdZXPzS6dXxJpTTnxT5sIHx6U9KuT25g6fiGVHGmQ3lxtKXdhviX3jnqROnICFLswG+VgPKgmxyQQsgt061NjmYEFwHwsAOFXvw9bK0KasoijiixJpf5A/TDBjXLa2wzIriKjzMV+JiIiIiGStCdrwzfi4Cjl6BX4yxIhnw5R4qASgZEEeHF4Rff9TKjn3s/W1UAvAVQOlIy3/caAekdw53Ij/G5OM69fU4KvS5jVd2V8fy5cTl47bfBBFsUdMqPiuIvw0FwAYna7G42OR7NyWAAAgAElEQVSSI14TSZZBvpTk4xNOjM2S9qOwe0U0eJsDKDolMClH0+bPTUTdgxkWRERERBTC7ZO/W17m8IcNVgBAjkEJtUJAskaB+YNCAwrLjjQE/r/W5ccvN1nw4XH5PgRfzcnE5rlZWDTODINKgbcuTsPtQ40oSlHhnrNMePL8lBi/qvhT7xWjHtEZz8oafPifby0Rr3ng7CRo2lHGI5dhAQA7qkP7VNQGlSilaRU9IihE1Nsww4KIiIiIQgRPdoiWs0Wg4/6zk7D0iLRcZNUpF0RRhE8Ervq8KmKDzZFpakn6vkGlwHMTzG1aVzw7ZvMiO0z2QKJ4fKu11WtmFeja9TnkelgAjb1Wnt9lwwMjTYGgRHDAwqzlfVqiRMSfXCIiIiIKsamV9P5wJmY3p90PNauxc152yDX/PdyABV9GngZy6xBjr+k1kOiNN/fVerAsKDAVbFaBrl3ZFUD4DAsAeHJbHb4tb37NWmQyLIgo8fAnl4iIiIhCrDweeQPa5P/OTUbLyaKX5Evvovc1hd4Vv/trCz49KV8GMjJNjSVTUvHchMQv9wj26zD9G47ZfIH/L7Z78fh3Vry0xw6vv/UmlvHg7RZlPnIEAAvPSWr351G3MsJ28ffNpUq1Lum/XSoDFkQJiSUhRERERCTx4XEHVp1yRbxmULISy2dkoF+SCkPNKrxz1IFzMtSYP1jaUFMhCEjVCiEbyHAeGpWEOT2gmaacO4YZcbreh9f3S5uMNpUvePwirvi0CsX2xgBGWYMvIfp07K0NzZS5sdCAFI0C31W4cWORAWent7/h5ZhMDQQA4V5JJ1pMXKl2+STnGLAgSkwMWBARERFRQKXDh7s21EqOnZWmxprLM/FNuQsVDj/yjEpMzm2eynB5Pz0u7xc+yPDCxFT8ZG1NVJ9/fHbPneRgUjf24BiVrsY9G5sbVDZNs/jspDMQrACAP/9gT4iAxQGrtKTlvRnpmN6nff0q5OQalLhjmBGv7os8VQYASuqlAYtw/S+IKL4x1EhEREREAR+dcKK+xThItQL4w/gU6FQCpvXRYf5ggyRYEY0r++vxziXprV43s0DXKzaWRpW0tKEpYLGjqm19Q7qTwyviRIuSFgHAhE4MOj073ozd12TjX1PTQs61zLxoGfgBgH4ypUlEFP+YYUFERESUYA5ZPXhpjx3pOiXuOcuEFE3H3YMqd0g3ercNNWJcdmwBCjmX5OswJEUVcje+SaZOgd+Pi/9sgo6gDwpYOLyNJSEtN/6J4nCdVxIoKDApYVB17j3RApMqJOgDAJ4WfTZblocAQL8kbnuIEhF/comIiIgSSKXDh1mfVKHK2bg7q3b68MeJqR32/HaPtENAbgeO27xusAFPbqsLfJyhU2D5jHRsrfRgap6212wqDTIZFp8WO/DesegancaTfUH9K4akdM33ME2nxIU5Gmwoa85KKXf4IIoiBEEIybCQa/5KRPGPJSFERERECeTRLdZAsAIA3jvmgF/suGkSdo90HKRJ3XGjRW8dYkROi9GU8wc1NmO8dagRA5J7R7ACCM2w2F7lwfVfyPf48MX5pJD3jkonhAxNVXfZ514WVGbk8QM1Lj8cXhHljubXsVIA8o0MWBAlot7zl4GIiIioi1hcfiw90oA6tx83FhqR18bNkl8UcbTOi3yjCjqVgJ1VbrxzVHoXvs4t4rDViyJzx2wU7V7pBtmk7rj7W2atAu/MyMA/9tuRY1DirhGmDnvuRKIPKpmo94YPSjT4RCS1Ms6zu/hFEV+XSftuzInQfLWjGVQKFKWocLBFmdHpBj+0CmnQLc+ohCpO/w2JKDIGLIiIiIg6kNMr4uKPKnG4rnET9d5RB9ZfmQWtMrYNk8Mr4rJPK7GjyoN8oxIrLs3AJyedstc+v8uGVyaHNiGMZG+tBxoFMDhFGuiwBZWEmGR6BbTHyDR1h5awJCJDDK+FBo+IpK5LWojJCZtPEmwxawScl9m1i80xKCUBi9vW1WBkmnQNLAchSlwsCSEiIiLqQF+VugLBCqBx5OO/D7Y+hjHYm4fqsaOqsT/AqXof5n1ehR9qPLLXLj3iwHGbfDNLOb/ZasXEDypw3vIK/HZ7neRcaEkI3y52tOCSkEgaImRfdLc9Qf0rhqeqIQhdm8kwIlV6//Wg1RvSCySnF0yeIeqp+BeIiIiIqAOIoojFO+tw3ZrqkHMPbrLiue9tMT3fiuPSTddRmw+fFMtnWADAn3ZH9/z1Hj9e2mMPfPzc9zYcsDRvPIObbiZ1YA8LahTcdDOSSOUi3W1vUMBiRBf2r2hyxzAT9K1krCRr+BomSlQMWBAREVGP4/WLeO57G+avqcbyoKaAsah2+jDnsyoMXVqKF1ts8uW8f8yB3+0IHzT47fa6kA1eOFa3H5sq3K1f2MK7Rx2oD8qOkHOkzgt30GXrTrsAAG6fiO+rpWvsyKab1CiWgEWDt/XvaVdzeEVsrXTju6DX6PBuCFgMSFbh7UvSkaoN/2+axCwhooTFn14iIiLqcf51sB6/3V6Hz046cetXtVh6WBq0qHT4cNzmhbeVCQwPfGPB+lIXyhx+PLbFik3lrpBrvH6gvMEXtr9ES1+Xhj5ezpclTkQRe5CweUS8vLf10pNvy0MDIZYzEYwNZaHrS9Px7WJHUyuA5CgDQSdsvtYv6kLfVbgx5r0yXPxRJVaXSF8vI9K6pz3ehbla7L02N+z5ZA1fw0SJij+9RERE1OO8H1TD/vMNtRBFEaIo4qdf1aBoaRlGv1uO8e9XhO0LcdzmxYoT0iDEpZ9U4S8tSi+OWL24cqsOQ5aV4d2g6R1yTtZHt/n8LIrgBwDcP1I6ZeO32+tQ6Qj/OY7bvHh6R13I8VpXY8CitEH6WK0SyNCx/r+jCYKAInN0m/vgfgydQRRF7Ld4Ir52Dlk9MC8pwSUfV+J0g3w0bVg3ZFg00asE/GmiWfYcy5qIEhcDFkRERNSjnLR7sbEsNIvgqs+r8VGxE+8cdaApr+JwnRczP64MSW0HgNf2yWcrPLGtDlXOxo3dH3fbUOGO/u3UKXt0AYu9ta030Mw3KnFjoSHk+IfH5Te4TcEaqzs0q6QpYFEf1L/i2oGhz08d41fnJkd13ZpTTliDa3g6kMXlx7SPKjH+/QoMf7sM78qUUO2u8WD8+xURn6evSdntpRcX5GhkjzNgQZS4GLAgIiKiHuWRzVbIFXqsPe3Cgi9rQo7Xe0Xct7ExA6NJtdMXtmeFV0Sg+eXWSvk+E0PNKqybnYkVl2ZIjp+sDx+I+KHGg0e3WPDW4QactLcesPjVuckhI0mBxuyM9aUu+M98PTVOHz445sC81dX4rlI+m8RyJogR3OAxneUgnaZI5nsnxysipgkwsXrjYPM0Go8f+P1OaR+W8gYf5q+uhq+V3p/d0b8i2IAkFXINoa/ZJJaEECWs7ik0IyIiIuoEn5104OMIkzTC2WvxYm+tFyPS1Pi02IHrvwgNbLT08QkHJuVosd8iv5F89JxkjM7QhGw0w2VY1Dh9mP5RBVw+AAjN7JjTT4dUrQIjUtXYUObC+Gwtrh2kBwD8flwKfrnZGrh2TYkLa0pcuHagHk+PS8H49ytQ5Yx8h94SyLCQXmeMoTkkxUZuY93k/Ey1JLhk83TepJAtQdlFB61e+PwilAoBoihi+keVKGloPTMoeLxod1AqBDx2bjJ+8bVFcjzafiFEFH+6/zcLERERUQd58YfIkzwimf5RBU4vyMNDm6ytXrvqlAurTpWHHJ83UI+L++gwp39jMCHPoIQABDI+yhx+WFx+mLXSzera064zwYpQ/ZOUeGNaeuDjO4ZL+1bkGOR7TLx91AGviFaDFUBzSUjwSFMjpyt0GkEQoFcKcASlLqybnRnSZ6SuE0tC5F4flU4/cgxKvLy3Hqei7LvSHSNN5dww2IA3DjRgy5nsJ7UiPrI/iKht+FeIiIiIeowDVmlGw/sz0sNcGcrpA57daZPdoP3q3GQMSIrcfPLes0x4/aI0zB/c3PdBoxSQrJHe3f2fby3BD0WNK/yGNC9MQKJJlj7827nlUTZstJ/JrAguCeFI08513ZksmSaLxqZgdIYmZKrFDV/UIPuNEjy2pfVgWqxOymT9DF1WBvOSEjwa5vMFjxDN1Ckws0DX4WtrC4Ug4I1paZiap8WAJCWen2BGpp6NY4kSFQMWRERE1COIoojqoLvFE7K1MMVQ1vBsUP1+kx8XGjC7n172XJP7giZ2NOmfJE1oXX7MEegv0aROphFmk2l9Im8EszpgM9aUWRGSYcGSkE5191mmQMBpUo4GtwwxApBvEunyAS/usYedatMWdo8fp6Mo92gyNlOD4zfk4sj1uVgyJRX9TEqMTlfj3RnpcZWNk2NQ4v2ZGdgxLwcLiozdvRwiaof4+c1CRERE1A7fV3skjQFNKgE6lQC3v331/7uuyUauQYkr+oUPHKydnYn0MOM/p/fRhhzbWSXddIabAqESGvtXRJJvVEIRY1zhN2OkEyrs3saRryE9LJhh0akKU9T4fl4Otl2VjRWXZkB3JkCUHGHzH+3I22hsq/TINqgN58YiA8xaBRSCgLkDDPj+mhysm5OFUeny0zmIiNqLAQsiIiJKeC6fiCkrKyXH0s5MuPC2MV6hEoDjN+Sir6kxQ+L8TA1m5ocGH85J9uGcjPAbtl+OCh1f+XGxtFQjOGCRpVdgZr4W/5iShiJz5Pp7jVJAgTG2LIuz0tTQtniIXwQcPhF2b3CGBd8qdja9SsCgFBUUQnNwKNJUC20Hfku+CzPlRs7tQ4348WCOuSWirsW/QkRERJTw1pe6Qo5lnAlYBGcTAEC6VoEPZ6bDEKHk4ZJ8naQ5piAI+OfU0J4Yd/ePnKKvUwl45cJUybE/7LLjF1/Xwncm+8MaVBKyaGwKll2SEWje2ZpBydH3UR9uVuGiPC1MQcEIu0cMCZzIlSZQ54s01aKtATg5WypCf25ampSjwTc/yoLllj54boIZylhTeYiI2okBCyIiIkp4h6yh40VNZ9Lq5w82oM+ZxpVpWgXWXJGJvdfl4KI8Hd6ano4Z+VrcOsSIkWnNmQzDU1V4dnxKyHPqVQLWzc5EvlEJtQJ4eHQSRiW3PsFhZoEOyqC93puHGgKBluBAQUqEO+xy+kSZYSEA+NMFqVArhJCGmnaPiAqHdB1sVtg9hpjDB6DClQ/FShRFfH5KGrD419Q0zCrQYXyWBh/MTMdHszI5YYOIuhXHmhIREVHCOy0z2aNpE5+lV+LbuVnYW+vBsFS1JBhwUZ4WF+U1lnl4/CK+LnXBqBYwNiu09KPJ6AwNdszLhig2lmMcOhQ63jRYqlaBidkabCiTpuDvt3gxtQ9Q7pCuP3jsaWsiTQpp6emxKTg/q7F8JThgYXX7Q5qWZup4b6s7TMrR4seFBvz3UENIj4kXdjeO7n3s3GSo25Hx0PQ8TZLVAmb30+HKKLN6iIi6Av8KERERUcLbJJPa/rNhzdMBkjUKjM/WRsxcUCsETO2jixisaHmtJjhlohVXDQit/6/3ivD5RRypk2aItDZCNVi4hp8t/Xd6Gu4c0TzJxBTU2PGa1dWSzXGqNvavkTqGUiHgxUmpqL2lD16bnBpy/oXddnwQ5cjacN4+0iD5eEymRtJHg4goHjBgQURERJ3G5ROxvtSFvbUdN4oxWJXTh22V0ue/uciA0REaYXaHBUWhAQu7x49iuw+uFgkW6VpFVAGIlnxi5MYGk3O1mFUgnTZi1kg3p1VB2RXZLAeJC+Gybf64S34EbzRO2b3YZ5EGya5nQ00iikMsCSEiIqJOUd7gw4yPK3HC3rgbf3BUEn51bmgDzPb6osQlyQwYblbhhQtC70p3N5VCwDPjUvDIZmvgWL1HxH6LNNhSFKF/QThFKaF9Bp4Zl4IpeVpUO/0Yn6WBEHT3/PJ+eqw6Fb7pYn6Mk0eoc5ydpoZCaJzk0tJRW2jflmgdt4eWUF0zkKUgRBR/mGFBREREnWLhFmsgWAEAz31vw6fF7Utjl7P6lFPy8WV943fjZQyaSvLa/npc/0WN5NjQNgQspvXRSgIMi8am4OfDTRhqVuOCHK3sdIebioy4a4Qx5HiTeP537E2yDUrcMSz0+5TVjgwYZ9CokWl52pCAFhFRPGDAgoiIiNrF5RNRbPfC36IsYVO5C8tlauzvWF+LAxYP3L6Om8247rQ0S+CS/NZ7UHSXJHXrb73ksiVao1YI+OKKTDxxXjL+NTUNPx8ePhDR0mPnhM94mTuAAYt48fiY0Ik1Ge1oiOoM+vnTslcJEcUploQQERFRzIrtXnx4zAGTWoHF39fhdIMfk3O1WHZxOvQqAatOOmUfZ/OIGPd+BQDgir46vH5RGnSqtm+WXD5R0ntBKTQ2D4xXRnXrX2ukkZaRZBuUuG9kUozrUWBEqgp7aqXlBQOTlEiNcVIJdR69SsDyGem46vPqwDG7p+1Bv+CAhb4dP4NERJ2Jf4mIiIgoJjVOH6avrMT/ba3DA99acLqhMWCwvtSFV/baUd7gw5ID9a0+z0fFTvzph9gbB/7rQD3mfV6Fv/5gg9UtbRSZolFA1Y5Rj50tuCRETlFK195P+t3Y0Lv3z443d+kaqHXDUqWZN7Uuf5grW8cMCyJKFMywICIiopj8cbcdlU75zdIT2+rwxLY6yTEBQF+TUtLPosmiHTYIAB4alRRVDf07Rxpw3zcWAMCaEhfKGoIDFvG98TK1kmFhUgno08XNLqfk6VB+Ux5+u70OG8tcmDfQgEvyda0/kLqUOWgkb63LD1EU29R7IriHhZ4BCyKKUwxYEBERUUz+8oM9puvvGGbE/MEGTF1ZKXv+6R02/OdQA775URaMEXo8iKKIRTukwZC/7pGuJUUT38mjGa2MKy0yq7ql+aFWKeCp80MzLSh+6FUCdErAeSbu5xWBeq/YahBMTmiGRUeskIio48X3X3UiIiKKK9XO0CyJSApMSvzfmGQMSIp8j+SE3Yeb19ZEvGZLhRtHbZE/f7wHLHINCvQ1hd8ddnU5CCWW4L4iTWUhp+xevL7PjjdPqVDeEPlnxOLyY3XQOFv2sCCieMW/ikRERBSVnVVuXP5pVUyP+eMEM0xnsibStArURKi7X13igs3jDztJY9mR1keixntJiCAIuChXi38fapA9P8Qc+4QQ6j1SNQqUtiiD+vNuO07W+/BZoMmtBu9VVmLHvGyoW/RyEUURNS4//CJw0YqKQN+ZJjqWhBBRnIrv2xBERES92HGbt9W7pV3lkNWDaR9Vot4b/WSCh0cn4eIWvRB+XGho9TEnwmRQfHXahX9E0cgz3jMsAGBKXvixq8ywoEjMQRkWr+2vbxGsaHSq3ocdVe7Ax5UOH8a9X4FBb5WhcGlZSLACYMCCiOIX/yoSERHFoUe3WPDSnsYN+vgsDR4anYTpfUIbIe6u8eBYnRdjszQotnsxMk3TKend7x11wB/DFEWVANxzlkly7NdjkjEyTY0GrwiLy4/X99fjVL00QHHC5sVZac1ZBntqPPjTbhvePtp6dgUA5HZxw8q2mJwbPmDR1pGm1DsEByzCqW8x8vS32+tw0OqNcDUDFkQUv/hXkYiIKM6UNfjwyt7mbIJNFW7M+7wab1+SLpnesPKEAzd9WYOWcYQ8gwJLL07H2emaDl3TFyXOiOczdQrYPP5AQ8BbhxoDpSBN1AoB1w5qzrK4/+wkPPBNLZYcaC6PON5iksh/DtXj7q8tMa3zsoL4n26RqVciR69AmSP0Tnf/Vnp9UO8W3MMinKZpvw1eP/51UL78qCUde1gQUZziX0UiIqI48++D9SHZDCKAn62vxfWDDVAKwPQ+OizcbEVw0sPpBj/u/8aCL2dndeiahprV+K7SE/b86xelYWyWBtur3FArgPMzowuY9DNJ34o8tsWKx7ZY27TGi3K1GJWeGD0g/nRBKq5bUx1yXKXgxpHCS42y5MnpE7G53IX1pa7WLwZQGielZ0REwRiwICIiiiO7azz43Q6b7Lkalx8vnhnj+ecIo0W3V4UPLMTC4xfxqy1WbCx344ea8M9ZYFJiYo4GaoWAC3LClzvIaUtGwbPjUnDA4sW6005olQLSdQrM7qfH7UON3TIStC1mFujwhwkp+N9vm4Mzvx/HsaIUWbQlIT9pZeJOsMHJ3BIQUXzibyciIqI48vKe8IGIWDi9YrvTvH+3vQ6v7pNvdPn7cSk4avOi1uXHfSOTJBMJYtE/KfqeE3uvzUFeAvSoiNZNRUbsr/Xi42IHLsrT4Zahxu5eEsW5VG3HB+RSNIKkOS4RUTzp1lbaGzduxPz58zFs2DCYzWb85z//kZy/8847YTabJf9dfPHFkmtcLhceeughDBw4EHl5eZg/fz5KSkq68ssgIiLqED6/iP8ebr3ePBp1nvDjQ6NRbPfihd3hgycFJiWeGWfGq5PTMDy17WUYA6K8szt/kL5HBSuAxp4eiyeYsfe6XLx8YWqbgz7Ue0RbEhKtm4sMWDc7KyGm6xBR79Stv53q6+sxfPhwPPPMM9Dr9bLXTJkyBQcOHAj8984770jOL1y4ECtXrsTf//53fPLJJ7DZbLjuuuvg87EWj4iIEsuuCGUXsapzty1g4fSKWLjZgrPfKY94XXBDzbZK0SgwpJVRnsPNKjxyTnKHfD6iRBZtSUg0TCoBz443Rx00JCLqDt36G2rGjBmYMWMGAOCuu+6SvUar1SI7O1v2nNVqxb///W+8+OKLmDp1KgDg1VdfxciRI7Fu3TpMnz69cxZORETUCb46LW2Ql2tQoLRBGnh4ZHQS5g3UI0OnxO1f1WB7lQfXDdJjfakLe2qbRxfWuWOYQdrCb7fX4eW98mUgLZnUHZcNMDlXiwMyYxdrbs6DT2wckZoovSmIOlO0U0LkFJiUeOycZPx8Qy10SuDZ8SnQcpwpEcW5uM//+vbbbzF48GCMGTMG9957LyorKwPndu7cCY/Hg2nTpgWO5efnY8iQIdi8eXN3LJeIiKjNvgrq6P/gqKSQa0alqzE4RQ2zVoF3Z2Tg6A25WDTOHLKRaUtJyJclTry8N7oeGh0ZsPjFWaaQYxOyNVAIAtQKgcEKojPaE7Cwuv2YP9iAmpvzULogDz8uZM8UIop/cZ0DdvHFF2P27Nno168fiouL8dvf/hZz5szBunXroNVqUVFRAaVSifT0dMnjMjMzUVFREfZ5Dx061NlL71CJtl7q2fh6pHjR016Lbj/wTZkeQPPmvJ+7DEOMWhyob9ykKCEi034Kcl+60q1Byz/rB06cRp/66Msj3zilwl+ORzeKFACqTx0Hwv+pjdnzwxX4n73Njf9Gae04dMjScZ+gk/W01yPFJ58IJKv0qPPGHsSbkurh65S6FF9vFI3CwsKI5+M6YHH11VcH/n/EiBEYPXo0Ro4ciVWrVmHOnDltft7W/lHiyaFDhxJqvdSz8fVI8aInvhZXHHfA5W8eRdjHoMT0kYPgMTtx+1e1cPhEPHZuCs4bni/7+NzSGqDGEfhYSMlCYWFo5oIct0/EPzeXAoiujCTfqMS44YM7NPOhEECfPCf+sd+OIWY1HjknCQZV3CeCAuiZr0eKX1NOVWPFCafkWLJGiFgGJgC4c0wOCrNjGztM1Fb8vUgdJa4DFsFyc3ORl5eHo0ePAgCysrLg8/lQXV2NjIyMwHWVlZWYMGFCdy2TiIgoJrtrPLhpbY3k2PlZGgiCgFl99Tg4Xwu3P3I6eJFZDaA5YPH20QbcMTy6gMWWSjdsHulm5/K+OrwyORVWlx/TPqpEhaO5xGRGvq5TyjRmFugws4DjFYkimdZHFxKwyNIpUecO7QMzM1+Ly/rqcV6mBiPS2j7Nh4iouyTGrYszqqurUVpaGmjCOXr0aKjVaqxduzZwTUlJCQ4cOIBx48Z11zKJiIhi8syOupBjg1t07jeqFa3Wrs/Il270t1Z6MOH9clzxaSXMS0pQ+FYp/vdbC1addKLSIS0V2Vbplnx8XqYa/5mejiS1AvkmFTbMycLsfjqoBODsNDUePTe0twYRdY0peaFZEsYwPWUu76fHT4YYGawgooTVrRkWdrs9kC3h9/tx6tQp7Nq1C6mpqUhNTcUzzzyDOXPmIDs7G8XFxXjyySeRmZmJK664AgCQkpKCBQsW4PHHH0dmZiZSU1Px2GOPYcSIEZgyZUo3fmVERETRqXH68HGxM+T4wGRlTM8zIlWFfKMSp1r0rdhnab7jWun04+/76/H3/Y0TQP5xUSquGmgAALy2TzoVZN6Z402yDUr8e1o6nF4ROhUbYBJ1p/5JoW/fC1NU+L5aOhZ5bKYG8wbqu2pZRESdolszLHbs2IHJkydj8uTJcDgcWLRoESZPnoynn34aSqUSe/fuxQ033IDzzjsPd955JwYPHozPP/8cSUnNd3YWLVqEyy+/HLfccgsuvfRSGI1GLF26FEplbG/0iIiI2ksURfhFEV+ddmLmx5W4bk01SsI0vhRFEe8fa8CED0I7VyoEYGJObLXmgiBgYnb0TTOf2l4HURSxZH+9JMgBAMNT5e/GMlhBFB+eHZcS+P/BySqMlMmgWHV5RsL0gSEiCqdbMywuvPBCWCzhO4AvX7681efQarVYvHgxFi9e3JFLIyIiismGUhce3mTBAasXvhbtIG5oqMba2ZlQBPV8+Nu+ejy82Sr7XC9OSpW9i9qaawYZ8PZRR+sXAjhm8yH1n6dDjuuVAkanM32cKJ7dMcyIAUkqnKz3Ym5/PV7fXx9yDccBE1FPkFBNN4mIiOJRrcuPG76oDmlcCQDfV3uQ/cZp3HOWCY+dkwylQkCd24/nd9lkn+v7edno14ZgBQBM76NFH4MSJQ3RjzNtSQDw0oVmJGt4V5YongmCgBktGtQ6fdFN+CEiSjQMWBAREbXTlorQKRstefzA87vsGJisQpZOiWvXVMted0GOps3BCgBQCAJ+uDZbNnMiGm9MS8PsfkVjPK0AACAASURBVKx5J0o0Di8DFkTUMzFgQURE1AZOr4jfbq/DX/fYo37ML74OXwYJAPePbP/0DUEQkGdQ4HSDX3J845VZuODD0H4ZTWbmaxmsIEpQzLAgop6KOZ9EREQxcHpF/PUHG3L+fTpisOKnQ41RP+ftQ434aFYGLgkaTdpWd58lDXw8MNKEEWlqbL86G7cOMeLyvjqktxiTKgB4aHRyh3xuIup6FwY16c03svk8EfUMzLAgIiKScdzmxf99Z8Xpeh9uH2bCiFQVRqSqcetXNfhEZgxpSy9OMuPHhUY8My4FWW+cRqSbnzvnZbepwWYkNxUZ8No+O47bfMgzKHDPWSYAwMBkFZ6faA5ct/xoA7447cJlBTqclxn9hBEiii+z++sx9Hsb9lu80CgafwcREfUEDFgQEREFsbr9GP1ueeDjbRtqY3r8ORmNm3+lQsCfLjCHLQW5ucjQ4cEKAEhSK7D1qmz8UOPB8FQ1NEr5aQFXDTTgqoGGDv/8RNS11AoBX1yRiXe2H8OkoX0xOIWTfoioZ2DAgoiIKMiqk5EzKMJRCY19KIanNm8Wbiw0YmCSCn/YZYPDK+KbcjcAIFUr4P6z29+zIuxaFAJGZzBrgqi3MKoVuCDNz2AFEfUoDFgQERGd4RdFVDv92FPjifmxz41PwTWDDEiRGQk6MUeLiWdqzOs9fuyzeFGUouL4UCIiIqIIGLAgIiICUNrgw81ra7C5wh3V9QKAr+Zkosrpx+h0NdJ00TW5M6oV7BdBREREFAUGLIiIqFfz+kV8dMKJhzZZUOn0y16zaGwK9tZ6cKSuMTNifLYWU/K0yDGwEz8RERFRZ2HAgoiIeq0TNi8mfVgBmyf8GA+1Apg7QI87R5i6cGVERERExOJZIiLqte7ZaIkYrEjRCHhuvJmZFERERETdgBkWRETUK1U4fFhf6go5nmtQ4J6zkjAxW4Oz0tRQKeRHghIRERFR52LAopfaVO7Cg5usAIDfj0sJdK/vLKIo4tOTTpTU+3DNQAPM2sjJPSX1Pnxf7caEbC1SW7mWiChWflHEX3+whxxfeWkGLszt3N+HRERERBQdBix6Ib8o4o71tSi2+wAAN62twa5rsmFQdV5g4M8/2PH41joAwD8P1GP9nCwow9y13FnlxsUfVcJ7Jkt7cq4Wl+Rr8dOhJuhUHXunc32pC6/stWNAkgqPnJOEJDWDI0Q9ncMr4kerqkKmgdw21MhgBREREVEcYcCiF9pW6QkEKwCgyunHJ8VOzBto6JTPZ3H5A8EKANhT68XWSjfGZctvDJ7fZQsEK4DGoML6Uhc2lbvxn+npHbauYrsX16+pRv2ZT+YXRSwaZ+6w5yei+PTIZovs6NIf9dd3w2qIiIiIKBzeTu6FPjvpCDn29/31nfb53jgY+tx7ar2y11Y4fFhxwil77uNiJ9L/WYLvq0M3Gm3xlx/sgWAFACw74oAohm++R0SJ71idF/862BBy/BcjTMyuICIiIoozDFj0Qp8WhwYEvi13442D9Shv8Mk8ou2cXhGv7g0NWOyt9YQcO2z1oGhpWcTn84nARSsqsfqUfFAjWvUeP946JN201Lj8OGiVD6QQUc/wukxwdkGhAU+en9wNqyEiIiKiSBiw6GU2lbuw1yK/Kb93owXnvleOH2qkwQSnV8Rxm7dN2Qf/PFiPEpkgyOv76/HEVivKzpz77KQD5y2viPp5r1ldjTs31OI3W60obUOQ5d2jDti9oV9PWYM/5uciovjn9YuY93kVXtwjbbT54Kgk/GVSKhQCJ4EQERERxRv2sOhF7B4/Lv2kKuI19V4RT26z4u1LMgAA+2o9uOzTStS6RFxaoMN/p6fF9MZerhykyR932/Hqvnqsn5OJBV/WRP2cTd463Jgh8WmxE3+YaMZBixcjUlV441ADnF4R94004ex0jexjlx8LLYsBAKubAQuinujXW61YUyIdYZqkFnDHMGM3rYiIiIiIWsOARS+x3+LB9Wuqo7r281MuPLuzDjcXGfG77XWodTVmInx20onR75bjDxPMuCRfF7j+6zIX/rzbBo8fuDBXi4FJKlyQo8HqU07sDdOrokmDVwybWTGzQIfPTzrRWl7HAasXV3waGoj58rQT267KRppOGfQ5/dhY5gq5HmDAgqinWnUytIzsn1PTkKVXylxNRERERPGAAYteYF+tBzM/qUSdO/qSjkU7bPjH/nqUO6Qb+GK7D9esrsYvRydBrxSgFICnttfBc+aytaflAwGxKv5xLpI1ChTbvah2+jE6XY0Tdh8mfVAhW8ohp9YlYuBbZRifpcEFORrM7qfHqHQ1dlV7EO4pLAxYEPVI1qDff/eeZcL0ProwVxMRERFRPGDAohd4YludbLDipUlmlDn8WHKgHiftoX0ggoMVLf1+p61D19jST4cakaxpbK/S16RCX1Pj8f5JKrx9STpu+KIalhiCL5sq3NhU4cYfdtlxfqYavggPDd7UEFHPUO+R/mz/cnRSN62EiIiIiKLFpps9nF8UsaFUmvUwKl2NdbMzcUOhEf9zdhJ2X5ODh0bFz5v3oanh42gTc7RYfUUmxmbK96ZozXeVHmyvCp1Q0uTFH+xhzxFRYvL5RThaRCoFAAYVm2wSERERxTsGLHq4knof6lvUP6gEYN3sTIzOkG74bx5iRLK6897A/6TIgAFJ0dWKj83SRjxfmKLG51dk4vgNuXhhohnzB+k7YokAAIdPxGFr+IAGESWe+qAaMKNK4FQQIiIiogTAgEUPd8gqbXp5boYGgswb9T5GJXbOy8ZNRYZ2f87gwMSgZCVemGjGk+enRHxchk6Bp8emYGSaOqrPY9YqcPMQI16ZnAbLLX1QflMeym/Kw6kbc5GsiW4zIneT9bzlFfikWH6KCBElHntQOYixE4OzRERERNRxGLDo4Q4GBSwKzeHLLdJ0Stw1wiR7Lt+ojJghcesQI5ZMScU3P8rCNz/KxsAW1z52TjIEQcCsAh1uG2pEnkGBYWYV9EoBAoA5/XQ4vSAXh6/PDfv5o6FVCtAqBZjUCvzv2c0lLkoBUITZn5TelIfrB4cGaW74ogbvHGlo81q6gsXlx6+2WHHHVzX4vtrd3cshilv1Xmk/HiPLQYiIiIgSAptu9nAHLdKARVFK5G95f5P8+TempmF1iROLdoQ22xydrsavxyTDrG2Of62+IhMfFztRlKLC+OzGEg+VQsAfJpjxhwlmAIDXL8LmEZGq7fi42T1nmeATga2VbswfZMDyYw58cFyaNbF4fArUCgEvTTKj2O7FxjLppn/hFisu66uDUR2fcb0ntlmx5EBjUOXTk05886MsFIT5/hH1Rj/UePDr76z4Mmh6Ubz+TBMRERGRFN+19XAHg/oxFLYSsNDJ3Hn82TAjzs3U4OYio+R4gen/27vzsKjq/Q/g7zMDDMOwDPsiCi6AkibuRobimqaZS5ltXh8z0+x2u2ZamdU1I/u51jVvZmZerUzNPa1McrlhWBpYmmIouQIiAwzLMMv5/UEMDDPAIDPDAO/X8/g8deZw5vuFL0fPZz7fz0eK8w+HIHlMoEmwAgD83aV4IlphDFZY4iIR7BKsAACJIOCfd3rh0yH+uD9SjghP8+yQ+L/GJggVgZSaM79ZZsCBy2V2GV9j5WsM+PRCVQZIkVZEt63ZyCzU1fFVRK3LM8fyzYIVAODJLSFEREREzQIDFi2UKIr4/loZjtXIGqgvwwIAno6tCkyEK6RY9FftiWAPKW5OCcPuewPw2RA/pDwQhCC51GJNDGfT1kLAoo2i6lhnpSs+G+pnds72ixVZGWU6EaU652h5+uFZNdp/eh0a80606L8jG3uzWH+DWhdRFFFYbkCpTkRaXjleSS1A3y+zkZZnuYCuJ7eEEBERETULzB9vYfQGEVoD8ERyHr65YvrJoqsEiPCq/0f+ei8fBMuluFGix9OxnnCTVv3j3kUiICG07i4ezsjHzTw251OjMOe9beVIHhOIxD25xmPfXC7DrkulmJOiws0yA+bHeWF+D2+7j9eSrCIdfsvXYu7xglrPKTcAS9OKMDpCjuslenxyrhjhnlJM6ugB12qFPLKKdNAaRHTysa7AKZGzMogiZhzJx9ZM6wN1fYJury0yERERETkWAxYtyIr0Iiw6WQhDLYkAHbxcTB5aa+PuIuD5akUrW4KuNTqPyKSwmBkS5++KaB8XY7FSnQhMSb5lfP3/0oowvYsC/u7WtWi1le+ulmHywTyUG+o/N7NIh+slegzcnYOc0oovmH1MhXtC3LCojw+WpRdhT1bFVpd727pjST8fqwJZRNWJoogLhTp4uEhMspUcSWsQ8fDBPHx31XzbhyVD28jQxdcVz3VrWfc3IiIiopaKTyktxM0yPRbXEawAgH7BrfdTxS6+rkgMkyH5r/3sb9bSYlUQBEzu5IE3fi60+LpeBDIL9Q4PWKw9o641WDEwVIbD16se2ArLRSxNKzIGKyodvVGOQdWyRwDgwOUyHL6mwYZEP4xo627zcVPLUKIzYFtmKdRaEW0UUiSEyvDaTwXYeL4EbhLggwRfjGvf+JbI9RHFihucIAgQReDpI/lWByu+GhmA+JDmlx1GRERE1JoxYNFCpOVpUVeJhd6BrnitV9NsZXAWXwzzx9eXyxDoLkG/OoqBPtTRA//6uRC1fTunfn8LwXIJpnfxxMMWWqLaw9dXan8o+3yoP3puv4HrJVUBii0XrG/JWqoX8X9phQxYkEXfXinDg9/m1fp6uQFYlq62S8BCpTHg37+pcSKnHEVaA7JLDCjSGfDMHZ5QlkqNNWYs6Rfkhp4BrgiUSxEf7FZnAWAiIiIick4MWLQQhXXsFVjYyxuz7zCtRdEauUoEjI6Q13teG4UUYR5SXC2xUNUSwJViPa4U6/Hz0XxEeElxVz0PQkVaA147UYjD18sQ7eOKd+9WIlBumwyNdQN9IXcRECSXmgQs1A0sEPpTrhZ6gwipFVuGqPXQ6MU6gxWVfr1l2/VjEEVszSzFgtQC5JaZ39sq2iub/95FeErxZGcFnuziCTkLaxIRERE1ewxYtBDVH1YrzYxVIKmfsglG0/wFeUhqDVhUt+Y3db0Bi0U/F2L9uWIAwB+FeozafxPv9PNBd39X+FmxtaSu7iR+f7WFDZFLkFbvleq2+FQhFvayvFWGWo5TN8vx2k+FcJUA7/RTomMdnYMWnKi9wGtN10v0CPds/F8p+RoDun1xo8FBt23D/DE0nFlCRERERC0J25q2ENkWHq4X9+XD5+2qDATU59iNchjE2h+sMgq0WHu2uMYxHcZ9k4cOn93AI9/lQa2tu5JmdmntgZPKcd5TR+cWX5mAXSP8cXB0YJ3vs/G89dtIqHkSRRGzjubjyHUNvruqwbB9uXjzZCFePVGAP9U6k3MvFenw8e/FtVzJ3B+FuvpPqofeICJuW8ODFSFyCQaFccsHERERUUvDgEULUTNtelW8EhILXTDIOnUVL63ulsZQ64OaSmPAAwfqTqf/6s8yLDxhucBnpR9u1F6/ws+94ld4aowCtf20h7Rxx8Awd/QOdMPIOupU3LSQek8tS77GgLOqqvV6S2PA0rQivPerGnduzcaEb27inz+okFOqx2OHbpnVxflxXBBOjA/C/RHm6+jv/1PVG3yry9l8LWK/uIGCcsu/fHXtNlnUxwcu3M5ERERE1OJwS0gzV64X8dHvxfi0RpFFpZUZAmRZQmhVR5H67L5UhoNXVbharMfwcHf8804vhCmkWH+u2KptJRvOF+OF7hVfU5Moiph1TGXx61wlQMBfAQuFqwQPRMqx45J5EcIgedVaSOrng//d0KBQa/mhUGcQ+eDXgmWX1h1QqOi4oTFuYaruP/f4IkZZ0R5442B/bM8swbTD+cbXs9R6xG3LxuH7gxrc5lQURcw4km9xfIdGByLYQwpfmQBXiYDFJwvxU245vPQl6BCkxOA2Mgxpw60gRERERC0RAxbNRInOgJTscvjJJOgRUNWe9B8/qMyCFQDg7cqHzsZ4pJMH1pxRm7UGtWTRyaoMiXW/F2Pd78WY3lmBD61MpzeIwJozaizq4wOtQcSXf3U+GNZGhvMFtafZP9LJAx4uVcGItp6WHxLDFVW/5pFeLtg7MgAHLpchPkSGKYduIU9TNcfR+29i54gAuLeQgoWF5QbsvFQKFwEY396jxczrdlmzni2J9XXBQx1NC9aOaOsObzcBhdUyIm6WGbD+dzVeraUWit4gwgBAb6gIuFUW6bxarEf6La3Z+X+L9kDPQNN2zK/3rrh2RkYGoqK47Y2IiIioJWPAohm4WqzHmP25yCyq+LR+UW9vPNvNCxcKtBaDFQDg7cYMi8YI9pDil4nB+D1fBxHAkL25xtdifV1wJr/u/frWBisqfXKuGDNjPRH7xY16z/1siB9kUgGJNfbsV8+kqK5m+v6d/m6407/iITBG6YIfssuNrx3PKcc7ac23+KbOIOJ8gQ5tPaUQAMTvzMGV4orfm+0XS7F9eEDTDrCJ5dRRD6Uu6wb6mW0x83SVYF6cN15JNS3MuSxdjTndvVCmE02Kym7LLMGso/mobGjkKgHuDpFhSrQHZLV0MPpbjOK2xktERERELQMDFs3A5oxiY7ACAP51shDTuijw803zTyQreTHDotE8XCTGT3c/SfTD9swS9A50Q6iHFNOP5Nfz1ebWJvji0wsl+P6axizoUagVrQpWjI10x8h2lluzxvq6mh07NSG4zs4N8+K8MfbrmybHlqerMTPW02atVx0lu0SP8d/cxG+1BJO+u6rBtWK9xa03rUVdBVxrs7ivj8W1BQCzYhUwiCJerVGHJey/1wEA4yLlWH2PElfUepNgBQBoDcD31zT4/poGURY6lbzcwwtxAW5mx4mIiIio9WDAohnIrFHUUWuoeCB4sIPlB1eAGRa2NjZSjrGRFd/vby6X3dY1HurogYc6ehj/P3FPDk7VEXSyZGTb2n/mg8JkGBwmw6FrGoR6SLBjRADae9f9Kz4wTIZV8Uo894NpnYwvL5ZiRqxng8bWlK6odei2NRv11Uo9X6BtUQGLYq0BBgCeLgIEK4rs1twSsqCnN9oopNiXVYrvr2lMunMEukvwYpwXpnepfR0IgoAZXTzNAhaVdlwqRXap3iSLx5KMGluf/jvYD2Mial/rRERERNQ6MGDRDNTWvWFrpnmBxUrebsywsBcvG31vvVwbFlQaG+mO8e1rf4iTCAK2D/fH5WI9gtylVtdrGB3hjud+MD12Ircc00UREkFAqU7ELY2hwYUUHSWjQIs+X+ZYde7vKh0Ghdl5QHam0hiQWajDWZUWL/1YYCyg2lnpgsQwGWbd4Ym2tWTV1NwSEiSXYHInD0zuVBFIO5OvRVaRDgNCZVavTzepUOc2qfqCFTV5uAgY0oYtSomIiIiIAQunZxCBg1et61ZRnbyWPeHUeJ4NDDQAwJt9vM2O3SyzPj3/zT7eeOYOz3o/RRcEAe3q2AJiib+7eSBiW2Ypdl4shcK1oqiiCODxKA/8PbhBl3aINb9ZXy9k6x8lmNFFYVU2gjNKzdHgsUO3LBbP/F2lw+8qHdacKcZXIwMQH1Lx0C+KIv5zphgncsuNBV0rBdfY9hPr61rr9o+6fDrEH3Hbsq0+f0k/H7yUWmCxffCwcJlJMVkiIiIiar34r0InVaYT8eqJAtz/U8Pb9XlYmR5Ot6eh9UHuj3DHFAvFAys/1a6NTAp093fF+oG+mN3Vy64/0933mhej1IlAwV/BCgD4b0YJzhQ53y3j6A3rA3o/39Ti6I2GfeLvLA5cLsW4r/Os6vTx4o8FuFiow/0HbsJ3wzW8lFpgFqwAgOBaCrU2VISn1GIdCkvOPBSCGbGeWNzHcmHXx6JYaJOIiIiIKjDDwknJpMC+rFJkaxr2QCERgLf6Ns8OD82Fp5UBiwci5Vg/yNesu0Kl8e098O5pNXL/2vLzdj8fyKUCdl0qRWIbGWZbkVFhK119rbsVfJUjxVg7j8UaZ/O1WH+uGOEKqVmNl/rcf+Amvh8T2KwKOl4t1mPa9/ko1tVXpaPCr7e06LG9/owHWxVWFQQBM2M98c8UVZ3nLe7rY6whMr2LAtdK9HjvV7Xx9VHt3LkdhIiIiIiMGLBwUoIgYHwHDyxNK6r3XKkA/DQ+GCIAFwkavCWAGsbTinT1AHcJPh7kW2fAoY1Cih8eCMLPN8vRO9ANAX9tzbCUjWFvvjIJJAIspuhXd13TdJk7+RoDVqYXYU9WqUnXnJo2JvrhxeMqiACGhrujvZcL3jxpWhTyxeMF+GZ0oJ1HbBupORoM33ez1tcnd/JAsFyClafVtZ5jiYtguwwLAJga4wE3KXA6T4sPzlrephPpWRUgcZEIWNTHB4v6+OBGiR43SvTo5udaa4CPiIiIiFofPtk6sQnt5VYFLB7q6FFvNwiyHZm04mGvtg+7/WQSrIpXWpUdESiX4t46On84iiAIiPV1xa+36u5acuSWC4bvzcWKeCXu8Gt4rYPGmHdchS/qKDQLAD0CXHF/pBz3R1Z9T0VRxN6sUvySVzW31NxyzDyaj3f6+zS4+KkjXVHrcO9XloMVA0LcMKmjBx6L8qjo1hHrib5fZqNIa10WRoSXFC4S2wUHBEGo2M4RVdFVZ9R+83HHKC3fp0I8pAjxcM6irkRERETUdJz3X+qELr6uiPU0/SR5YS9vVO9YKhGAF+70cvDIWjdBEOBTS9vY7CfCkPlIKO5rhi0Z77CwLSTSy/whMjW3vN7Uf1sr1YnYeanuYAUARFuooyAIAjYk+pkd/+xCCaYcugVRtO4B39FUGgO6bs22mPVyaHQg9o4MxOPRVQVEQz2k+CDB1+rrd/CyX5AzPkSGlfFKk2Mhcgk6MrBKRERERA3AgIWT+1dMOQaGyhDmIcHTsQo819UTC3tVdZx4uYc3OlpZ7I5sp2+Qef0DmRSQNePuLLO7eiHory0Cw9rIcO3xUPwyMcRikdGfc8uhrW//iA2dyC1Hef21JtGtlqyPSC8XbB/ub3b80DUNUhrYdtNRnjx8q9bXegRYnueodnLcnBKGu4Kr1ucDkZaDZ9387Zsh82AHOdpXC3j9Lab5dmchIiIioqbBJ10nFyEXsatGB4fZXb0wNlIOEaxX0VSmxHhg/+Wyph6GTXXzc8XJCcG4pTGgrUJqfLhcc48vph2+BU21ZB+dCFwq0iHKxz4PvR+eVWPVaTU6eLvg3buVOJlrHlR4tac3Dl4tw4mccujEik4Vj9bRYWJIG3fsHOGPcV/noXqoJTWn3NgC1FmoNAZ8V0s74+3D/et88HeRCPhqZADOFeigcBHQ1tMFyo+vmp33RLR9a6UoXCXYMSIAn10oQbhCikkd6+6KQ0RERERUE592m6m2DFQ0qWFt3BGukOJKcdVTfKcWkO7u6SqBZ42aDqMj5LgwORS9t2cju1pLzYwC+wQsMgt1mPdjAQwicKVYj7ht5t0u3uzjjdldvTCnuxfyNQZkFekQo3SF3KXuT/AHhbljbpwX3vmlqjZMkdaK1A0HO56jgaX8lUc6eWBwWP3BFUEQ0FlZ9bOJ8XHBuYKqbipx/q6ItOOWkEqRXi54qYd3/ScSEREREVnQpFtC/ve//+Hhhx9Gly5doFQqsXnzZpPXRVFEUlISOnfujJCQENx33304e/asyTkqlQpPPfUU2rVrh3bt2uGpp56CSuXY/fXU+kglAqZ1Nv2EetYdnk00GvvzcpVgVDt3k2N/FJi2Ez12Q4OEXTkYujen3uKddTl0tazebiVdfKsexn1lEsQFuNUbrDCeX6P+SKGVRSod6c8aXVDu9HPFH5ND8P49dXeeqc19EVU/O4kArKhRX4KIiIiIyBk1acCiuLgYsbGxePvttyGXm++zXrVqFVavXo0lS5bg0KFDCAwMxLhx41BUVPXp6JNPPon09HRs27YN27ZtQ3p6OmbMmOHIaVAr9WxXTzzZWYFYpQsW9PTGI51adsp7pxrZFBmFOmj0FQ/7BlHEs8fykX5Li59ytRhzIBcF1hSdqEFnEGttiVkpSC5BfPDtb+HwcjN94C+ycpx/qnV446cCzE1RYf+fpSjX2z7QYRBFaPSiWaePIW1k8He//S4af+/qhceiPNA30A3/uccXPQLMa7AQERERETmbJs1hHz58OIYPHw4AmDVrlslroihizZo1+Mc//oGxY8cCANasWYOoqChs27YNU6dOxblz53Dw4EEcOHAAffv2BQCsWLECI0eOREZGBqKiohw7IWpVXCQClt7Vej6pjqqx5WXj+RJsPF8CANg1wh8Xq2UF5GtERGy+jqNjg2othGnJx+eKkVEjc6OmfSMDrM6msKRmG1O1FRkWpToR476+iT8KK+b44e/F8JNJsPwuJYaFy7A8vQh5ZQbMvMMTMcqGb5PRGkS8faoQH54ttpjx4VVLVxprKWUS/HuA9R1EiIiIiIicgdN2CcnKykJ2djYGDx5sPCaXyxEfH48ff/wRAJCamgpPT0/069fPeE7//v2hUCiM5xCRbVhqcVpp7Nd5Fo+/e7rI4vHanLBQXLNSkFyCC5NDGl03w7tG15Oa2QyWbL9YYgxWVLqlMeBv399Cm03XsSxdjQ3nSzDhmzwUN7AmRkaBFjGf38CydHWt21MsdWohIiIiImrpnLZKYHZ2RaG9wMBAk+OBgYG4fv06ACAnJwf+/qYV8wVBQEBAAHJycmq9dkZGhh1GbD/NbbzUMhVoAaBh215OXC9GRoblYMZ3N6X4OleKHt4GPBymgyAAWXkyAFWBkQkhWrSVi1BIRQwJ0CP/shr5tz8FAICqSAKgqqZDblFJvb9jO393gzW3yyvFerx9LAtPhNedJVKpTA+M/UmOW9q6AxIlt3KQkXHdqmu2Jrw3kjPheiRnwbVIzoJrkaxR364Ipw1Y2FNz2irCrS3kLAyiCOmPV6GH9Z/2XyqVoEgZgZ6B+vzHlwAAFVdJREFUpjUT0vPK8fL/cmEQgeQ8wDcgAI928kB6SjZQrT/Gs33CEGfjegsGlRZIqwpoaqUyREW1q/Nrfj91A4C+znMqvXfJDe9dcsML3b2woGfdHTLmHVfhlrbumh0AENU2FFHtzOv8tGa8N5Iz4XokZ8G1SM6Ca5FsxWm3hAQHBwMAcnNzTY7n5uYiKCgIABAUFIS8vDyIYtUDjiiKuHnzpvEcIrINiSDA9TbuGIP35kL58VW8kKJCvqZiu8SKdLVJJ5BXTxSiw2c3UFqjkGWg/PYLTdamZg2L+oqDXivWm7SvtdbStCKk55Ujq0hnco8CgLS8csTvzK63wGilmmMmIiIiImoNnPZfwREREQgODkZycrLxWFlZGVJSUow1K/r27Qu1Wo3U1FTjOampqSguLjapa0FEtiFrxB1j3e/F+L+0QhhEETsulVr1NYHutr9FBcolJjkiOaUGlOlqr2Px3wzToELvQFd0rVFIVFFLEdCE3bnovi0bg/bkYvelUiTuycGAXTkYuDsXZ/LNt40s6OmNSR3NMym83VjDgoiIiIhanybdEqJWq5GZmQkAMBgMuHLlCtLT0+Hr64u2bdti5syZWL58OaKiotCpUycsXboUCoUCEydOBADExMRg6NCheP7557Fy5UoAwPPPP48RI0YwBYnIDrp5GXAs//azHt7/rRjv/2ZdVkGMjwvcpLZ/UHeVCAj1kOBaSVVmRch/r2FoGxk2DvaDh0tVkCT5ahmSTpkWDu0fJMOMWAWWplUcnxqjQFyAG946VYh3frFcZDQtT4snkm/VO7axke4IV3giNafc2HXFXQpEeLbK3XtERERE1Mo1aYbFqVOnkJCQgISEBJSWliIpKQkJCQl46623AADPPfccZs6ciblz5yIxMRE3btzAl19+CS8vL+M11q1bh65du2LChAmYMGECunbtig8++KCppkTUok0M1aKyw2a/IDecmhCM57t5wtZxhVAPCd7u52Pbi1YTrjAPABy8qjEJOOz/sxTjvjEtGCqTAn+L8UBbTxesutsXq+72NdbYeLmHN+bFeeF2fTTQF1E+rpC7CPjvYH9Eeknh6SJgUR8fKBuT2kJERERE1EwJKpWq/p5+1GRYsIacSUZGBlyC2+NqiR59A91MMiDS88px+LoGr54obNR7LO3vgye7eDZ2qHV68vAtbMu0vC1lYKgMGr2I4znmLVbXD/TF+A61d0rJLtGj+7YbKLOy5EUbDymOjw+qtUaFKIomXZCoCu+N5Ey4HslZcC2Ss+BaJFvhx3ZE1CDtvV0wIERmtl3jTn83PNu1YRkGU6I98P4ApfH/wxVSTOrUsNapt+PuYFmtrx2+rrEYrOjq51pnsAIAgj2k+HyoP+KD6+9s4ukiYO1A3zoLajJYQUREREStGTdGE5FNjQiX4esrmnrP85dJMC/OGyEeEvi5S3AmX4fx7eUO6Yhxf6Q7Xv9ZQEG59QlmHyb4WnXeoDB3DApzx7ViPWK/uGH2+hPRHpjb3QsB7lLIaynWSUREREREDFgQkY09180LP+Vqkacx4KkuCizp54Ofb2rxZ5EOIR5SrDxdBIWLBPN6eCFMUVHA8962ctzb1nFj9HeX4rMh/lh5ugjfWBFc2XNvALr4utZ7XnVhCinGRcrNOqIkhsnQlkU0iYiIiIjqxX81E5FNxYfI8MuDwdAbAB83AYIgoHegG3oHuhlfdwbxITLjWDaeL8b8HwtQYqG96ZRoD9wTentjXhGvRFpeOTKrdfwY4CTzJyIiIiJydqxhQUQ25+UqgVImaTY1GJ6IVuDyo6GYGaswe+2BSPltX1cpk+DLEQEYGCpDtI8L/j3AF4Hy228LS0RERETUmjDDgogIgFQiYFCYO9acKTYeC5ZLMOA2sysqRXq5YNe9AY0dHhERERFRq8MMCyKivwwPl+GhjnJIBCDaxwUbEv3gKmkeWSJERERERC0NMyyIiP4iCALWJvjh33eLZm1biYiIiIjIsZhhQURUA4MVRERERERNjwELIiIiIiIiInI6DFgQERERERERkdNhwIKIiIiIiIiInA4DFkRERERERETkdBiwICIiIiIiIiKnw4AFERERERERETkdBiyIiIiIiIiIyOkwYEFERERERERETocBCyIiIiIiIiJyOgxYEBEREREREZHTYcCCiIiIiIiIiJwOAxZERERERERE5HQYsCAiIiIiIiIip8OABRERERERERE5HQYsiIiIiIiIiMjpMGBBRERERERERE5HUKlUYlMPgoiIiIiIiIioOmZYEBEREREREZHTYcCCiIiIiIiIiJwOAxZERERERERE5HQYsCAiIiIiIiIip8OABRERERERERE5HQYs7Gz58uVITExE27Zt0bFjR0yaNAlnzpwxOUcURSQlJaFz584ICQnBfffdh7Nnz5qcs3TpUowYMQJhYWFQKpUW30upVJr9Wb9+vd3mRs2LI9ciAGzZsgUDBgxAcHAwOnTogBkzZthlXtQ8OWo9bt682eK9UalU4uTJk3adIzUPjrw3njx5EmPHjkW7du3Qrl073H///fj555/tNjdqXhy5Fg8fPozhw4cjPDwc0dHReO2116DT6ew2N2pebLEWs7KyMHv2bHTv3h0hISHo3r073njjDZSWlppc5/Lly5g0aRLCwsLQoUMHvPjiiygvL3fIPKl5YMDCzo4dO4Zp06bh66+/xu7du+Hi4oIHHngA+fn5xnNWrVqF1atXY8mSJTh06BACAwMxbtw4FBUVGc/RaDQYPXo0Zs6cWef7vfvuuzh37pzxz+TJk+02N2peHLkW//Of/2DhwoV49tlnkZKSgj179mDUqFF2nR81L45aj+PHjze5J547dw4PPfQQIiMj0aNHD7vPk5yfo9aiWq3GhAkTEBISgoMHD+Lbb79FSEgIxo8fb3Idar0ctRZPnz6NBx98EIMGDcKRI0ewfv167N+/H6+//rq9p0jNhC3WYkZGBvR6PZYvX47jx4/jnXfeweeff4758+cbr6HX6zFp0iSo1Wp89dVX+Oijj7B792688sorDp8zOS9BpVKJTT2I1kStVqNdu3bYvHkzRo4cCVEU0blzZ0yfPh0vvPACAKC0tBRRUVFYtGgRpk6davL1u3btwpQpU6BSqcyurVQq8cknn2Ds2LEOmQs1b/ZaiyqVCrGxsdi8eTMSExMdNh9q3ux5b6yupKQEnTt3xnPPPYc5c+bYbT7UfNlrLZ46dQqJiYn45ZdfEBkZCQC4dOkS4uLikJyczAAambHXWvzXv/6Fb7/9FkePHjUe279/P6ZOnYqMjAx4eXnZf3LUrDR2LVZat24dFi9ejIsXLwIAvv32Wzz00EM4ffo0wsPDAVRk6P79739HRkYGvL29HTNBcmrMsHAwtVoNg8FgTNHLyspCdnY2Bg8ebDxHLpcjPj4eP/74Y4OvP3/+fHTo0AGJiYlYv349DAaDzcZOLYu91mJycjL0ej1ycnLQr18/dOnSBY8++iguXbpk6ylQC2Lve2OlHTt2oKSkBI899lijx0wtk73WYqdOnRAQEIBNmzZBo9FAo9Fg48aNCA8PR+fOnW0+D2r+7LUWNRoN3N3dTY7J5XKUlZXhl19+sc3gqUWx1VosKioy2aaUmpqKmJgYY7ACAIYMGQKNRsO1SEYMWDjY/Pnz0a1bN/Tt2xcAkJ2dDQAIDAw0OS8wMBA5OTkNuvbLL7+M9evXY+fOnRg/fjwWLFiAZcuW2Wbg1OLYay1eunQJBoMBS5cuxeLFi7Fp0ybodDqMHj0aJSUltpsAtSj2vDdW98knn2DEiBEIDg6+/cFSi2avtejl5YW9e/dix44dCA0NRWhoKL788kvs3LkTcrncdhOgFsNea3HIkCH46aefsGXLFuh0Oly7dg1LliwxeQ+i6myxFv/880+89957mDZtmvFYTk6O2TX8/f0hlUob9Xc9tSwuTT2A1uTll1/G8ePHceDAAUilUptf/8UXXzT+95133gmDwYBly5Zh7ty5Nn8vat7suRYNBgO0Wi2WLFlijLyvXbsWMTExOHDgAMaPH2/T96Pmz973xkpnz55FamoqvvjiC7u9BzVv9lyLpaWlmD17Nnr37o0PP/wQer0e7733Hh555BEkJydDoVDY9P2oebPnWhw8eDAWLVqEuXPnYtasWZDJZJg7dy5SUlIgkfCzTDJli7WYk5ODiRMnIjExEc8884yNR0gtHe9KDvLSSy9h+/bt2L17t3HvKgDjp3y5ubkm5+fm5iIoKKhR79mrVy8UFhYyQkkm7L0WK68TExNjPObj44OQkBBcuXKlESOnlsiR98YNGzYgPDwcQ4cOve3xUstl77W4detWXLx4Ee+//z569uyJPn36YN26dbhy5Qr27t1rkzlQy+CI++Ls2bORlZWFX3/9FX/88YexMHb19yOyxVrMzs7GmDFj0KVLF3zwwQcQBMH4WlBQkNk18vLyoNfrG/0cRC0HAxYOMG/ePOMve3R0tMlrERERCA4ORnJysvFYWVkZUlJS0K9fv0a97+nTp+Hu7g4fH59GXYdaDkesxf79+wMALly4YDymVquRnZ2Ntm3bNnIG1JI48t5YVlaGLVu24NFHH+UniGTGEWuxtLQUgiCYrD+JRAJBEFhviowceV8UBAGhoaGQy+XYtm0bwsPD0b1790bPgVoGW6zFGzduYPTo0YiOjsZHH30EFxfT5P6+ffvi3LlzuHr1qvFYcnIyZDIZ4uLi7DQzam64JcTOXnjhBWzZsgWbNm2CUqk07vlSKBTw9PSEIAiYOXMmli9fjqioKHTq1AlLly6FQqHAxIkTjde5fPky8vPz8eeffwIA0tPTAQAdOnSAp6cn9u/fj5ycHPTp0wdyuRxHjx5FUlISpkyZAplM5viJk9Nx1Frs1KkTRo0ahfnz52PFihVQKpVISkpCQEAARowY4fiJk1Ny1HqstGvXLhQWFrLYJplx1FpMTEzEwoULMWfOHMyYMQMGgwErVqyAVCpFQkKC4ydOTseR98V3330XQ4YMgUQiwZ49e7By5Up8/PHHdt2WR82HLdbi9evXMXr0aISEhCApKQl5eXnG6wcEBEAqlWLw4MHo0qULnn76abz55pvIz8/HwoUL8cQTT7BDCBmxramdVa+EW928efPw0ksvAQBEUcTbb7+NDRs2QKVSoVevXli6dCliY2ON58+cOROfffaZ2XX27NmDe+65BwcPHsQbb7yBixcvwmAwIDIyEo8//jimT59uFs2k1slRaxGoqAL9yiuvYPfu3RBFEf3798fbb7+N9u3b22Fm1Bw5cj0CwKhRo6BQKLB161Ybz4SaO0euxeTkZCxZsgRnzpyBIAjo1q0bXn311UZnVFLL4Mi1OGbMGKSlpaG8vBxdu3bFvHnzMGzYMDvMipojW6zFzZs311qvIi0tDREREQAqAmwvvPACjhw5And3dzz44INYtGgRP3AlIwYsiIiIiIiIiMjpcCMvERERERERETkdBiyIiIiIiIiIyOkwYEFERERERERETocBCyIiIiIiIiJyOgxYEBEREREREZHTYcCCiIiIiIiIiJwOAxZERERERERE5HQYsCAiIiKHOHr0KJRKpfGPn58fIiIicNddd+Hpp5/GwYMHIYribV8/PT0dSUlJyMrKsuGoiYiIqKm4NPUAiIiIqHWZOHEihg0bBlEUoVarkZGRgX379uHzzz/HoEGDsGHDBiiVygZf9/Tp01iyZAkGDBiAiIgIO4yciIiIHIkBCyIiInKo7t27Y9KkSSbH3nrrLSxcuBCrV6/Gk08+iW3btjXR6IiIiMhZcEsIERERNTmpVIrFixfjrrvuwsGDB5GSkgIAuH79Ol555RVj1kRwcDD69euHlStXQq/XG78+KSkJzzzzDABgzJgxxm0nM2fONJ6j0WiwbNky9O/fH8HBwWjXrh0mTZqEtLQ0x06WiIiIrMIMCyIiInIajz32GFJSUvDNN9/grrvuwm+//YY9e/Zg9OjRaN++PbRaLb777ju8/vrruHTpElauXAmgIkiRnZ2NDRs2YM6cOYiOjgYAtG/fHgCg1WoxYcIEpKamYtKkSZg+fToKCwvxySef4N5778VXX32FHj16NNm8iYiIyBwDFkREROQ07rjjDgDAhQsXAAB333030tLSIAiC8ZxZs2bhqaeewsaNGzF//nyEhISga9eu6NOnDzZs2IBBgwbhnnvuMbnu2rVrcezYMWzfvh1DhgwxHp82bRri4+OxYMEC7Nu3zwEzJCIiImtxSwgRERE5DW9vbwBAUVERAEAulxuDFeXl5cjPz0deXh6GDBkCg8GAU6dOWXXdL774AtHR0YiLi0NeXp7xj1arxaBBg3D8+HGUlpbaZ1JERER0W5hhQURERE6jsLAQAODl5QUA0Ol0WLFiBT7//HNkZmaatT1VqVRWXff8+fMoLS1Fx44daz0nLy8P4eHhtzlyIiIisjUGLIiIiMhp/PbbbwCAqKgoAMDLL7+MtWvXYvz48ZgzZw4CAwPh6uqKtLQ0vPbaazAYDFZdVxRFxMbG4q233qr1nICAgMZPgIiIiGyGAQsiIiJyGps2bQIADB8+HACwZcsWxMfHY/369SbnZWZmmn1t9ToXNXXo0AF5eXlISEiARMIdsURERM0B/8YmIiKiJqfX67FgwQKkpKRg+PDh6N+/P4CKdqc1t4EUFxfj/fffN7uGQqEAAOTn55u9NnnyZGRnZ2P16tUW3z8nJ6exUyAiIiIbY4YFEREROVRaWhq2bNkCAFCr1cjIyMC+fftw+fJlDB48GB9++KHx3LFjx+Ljjz/G1KlTMWjQIOTk5GDTpk3w8/Mzu27Pnj0hkUiwbNkyqFQqKBQKREREoHfv3nj66aeRnJyMV199FUeOHEFCQgK8vLxw5coVHD58GDKZDHv37nXY94CIiIjqJ6hUKrH+04iIiIga5+jRoxgzZozx/yUSCTw9PREWFoa4uDhMnDgRQ4cONfmakpISJCUlYceOHcjNzUWbNm3w+OOPo2fPnhg7dixWr16NRx991Hj+p59+ilWrViEzMxNarRaTJ0/GmjVrAFQU8Fy3bh22bNmCc+fOAQBCQkLQq1cvTJ48GYMHD3bAd4GIiIisxYAFERERERERETkd1rAgIiIiIiIiIqfDgAUREREREREROR0GLIiIiIiIiIjI6TBgQUREREREREROhwELIiIiIiIiInI6DFgQERERERERkdNhwIKIiIiIiIiInA4DFkRERERERETkdBiwICIiIiIiIiKnw4AFERERERERETmd/wdswNL9UJsOcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Closing stock price history')\n",
    "plt.plot(df['Close'])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Price(USD)', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
